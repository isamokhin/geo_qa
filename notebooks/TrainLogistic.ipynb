{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "from ukr_stemmer3 import UkrainianStemmer\n",
    "from tokenize_uk import tokenize_words, tokenize_sents\n",
    "from perceptron_tagger.tagger import PerceptronTagger # POS tagger\n",
    "from qa_perceptron import AveragedPerceptron # model for parsing question\n",
    "from sklearn.externals import joblib\n",
    "from difflib import get_close_matches\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaned data from saved dictionaries\n",
    "with open('countries.pkl', 'rb') as f:\n",
    "    country_dict = pickle.load(f)\n",
    "    \n",
    "with open('cities.pkl', 'rb') as cf:\n",
    "    city_dict = pickle.load(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dict = dict(country_dict, **city_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_phrase(phrase):\n",
    "    \"\"\"\n",
    "    Also we can stem instead of lemmatizing...\n",
    "    \"\"\"\n",
    "    words = fix_hyphens(tokenize_words(phrase))\n",
    "    if len(words) == 1:\n",
    "        wparsed = morph.parse(phrase)[0]\n",
    "        if not wparsed:\n",
    "            return phrase\n",
    "        return wparsed.normal_form\n",
    "    else:\n",
    "        new_phrase = ''\n",
    "        for w in words:\n",
    "            new_phrase += morph.parse(w)[0].normal_form + ' '\n",
    "        return new_phrase.strip()\n",
    "    \n",
    "def fix_hyphens(sent):\n",
    "    \"\"\"\n",
    "    sent is tokenized with tokenize_uk\n",
    "    \"\"\"\n",
    "    new_sent = []\n",
    "    i = 0\n",
    "    while i < len(sent):\n",
    "        w = sent[i]\n",
    "        if w == '—' or w == '-':\n",
    "            new_sent.pop()\n",
    "            new_word = sent[i-1]+'-'+sent[i+1]\n",
    "            new_sent.append(new_word)\n",
    "            i += 1\n",
    "        else:\n",
    "            new_sent.append(w)\n",
    "        i += 1\n",
    "    return new_sent\n",
    "\n",
    "def gender_agree(w_parsed):\n",
    "    \"\"\"\n",
    "    Inflect noun phrase with adjective the right way\n",
    "    \"\"\"\n",
    "    gender = w_parsed.tag.gender\n",
    "    if not gender:\n",
    "        return w_parsed.normal_form\n",
    "    w = w_parsed.inflect({gender, 'nomn'}).word\n",
    "    return w\n",
    "    \n",
    "def get_matches(ent, all_ents):\n",
    "    matches = get_close_matches(ent, all_ents)\n",
    "    if not matches:\n",
    "        for entry in all_ents:\n",
    "            if ent.lower() in entry.lower():\n",
    "                return entry\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionParser():\n",
    "    \n",
    "    def __init__(self, obj_dict, model = 'perceptron'):\n",
    "        allkeys = []\n",
    "        for c in obj_dict:\n",
    "            for k in obj_dict[c]:\n",
    "                allkeys.append(k)\n",
    "        allkeys = set(allkeys)\n",
    "        self.pos_tagger = PerceptronTagger()\n",
    "        self.classes = allkeys\n",
    "        self.obj_dict = obj_dict\n",
    "        with open('units.pkl', 'rb') as f:\n",
    "            self.unit_dict = pickle.load(f)\n",
    "        self.lem_dict = [morph.parse(ent.split()[0])[0].normal_form \n",
    "                         for ent in self.obj_dict.keys()]\n",
    "        try:\n",
    "            self.ner_model = joblib.load('NER_model.pkl')\n",
    "        except:\n",
    "            self.ner_model = {}\n",
    "            print('No NER model found!')\n",
    "        if model == 'perceptron':\n",
    "            self.model_name = model\n",
    "            self.qa_model = AveragedPerceptron()\n",
    "            try:\n",
    "                self.load('qa_model.pkl')\n",
    "            except:\n",
    "                print('Please provide qa_model.pkl file.')\n",
    "        elif model == 'logistic':\n",
    "            self.model_name = model\n",
    "            try:\n",
    "                self.qa_model = joblib.load('qa_skl_model.pkl')\n",
    "            except:\n",
    "                print('Please provide qa_skl_model.pkl file.')\n",
    "        elif model == None:\n",
    "            print('Please train the model for QA.')\n",
    "            \n",
    "    def load(self, loc):\n",
    "        try:\n",
    "            weights, classes = pickle.load(open(loc, 'rb'))\n",
    "        except IOError:\n",
    "            msg = (\"Missing a pickle file for QA model.\")\n",
    "        self.qa_model.weights = weights\n",
    "        self.qa_model.classes = classes\n",
    "        return None\n",
    "    \n",
    "    def get_entity_pymorphy(self, q_text):\n",
    "        \"\"\"\n",
    "        Look for (capitalized) entities in q_text.\n",
    "        For this specific application pymorphy2 tagging is enough.\n",
    "        \"\"\"\n",
    "        forbidden = ['ВВП', 'HDI', 'ISO', 'ООН', 'UN', 'UTC', \n",
    "                     'Utc-Поправка', 'Utc-Поправка']\n",
    "        words = fix_hyphens(tokenize_words(q_text))\n",
    "        phrase = []\n",
    "        for i, w in enumerate(words[1:]):\n",
    "            if w in forbidden:\n",
    "                continue\n",
    "            if w[0] == w[0].upper():\n",
    "                w_parsed = morph.parse(w.strip(' ?'))[0]\n",
    "                w_lemma = w_parsed.normal_form\n",
    "                if w_lemma in self.lem_dict:\n",
    "                    if 'ADJF' in w_parsed.tag:\n",
    "                        phrase.append(gender_agree(w_parsed).title())\n",
    "                        phrase.append(morph.parse\n",
    "                                      (words[i+2].strip(' ?'))[0].normal_form)\n",
    "                        return ' '.join(phrase).title()\n",
    "                    elif 'NOUN' in w_parsed.tag:\n",
    "                        return w_lemma.title()\n",
    "                    elif 'UNKN' in w_parsed.tag:\n",
    "                        return w_lemma.title()\n",
    "                matches = get_close_matches(w_lemma.title(), list(self.obj_dict.keys()))\n",
    "                if matches:\n",
    "                    return matches[0]\n",
    "                else:\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "    def _get_ner_features(self, word, prev_word, next_word):\n",
    "        features = {\n",
    "            'word': word,\n",
    "            'word_stem': UkrainianStemmer(word).stem_word(),\n",
    "            'prev_word': prev_word,\n",
    "            'next_word': next_word,\n",
    "            'prev_stem': UkrainianStemmer(prev_word).stem_word(),\n",
    "            'next_stem': UkrainianStemmer(next_word).stem_word(),\n",
    "            'is_uppercase': word.title() == word,\n",
    "            'is_after_punct': prev_word in string.punctuation,\n",
    "            'is_after_uppercase': prev_word.title() == prev_word,\n",
    "            'pos': self.pos_tagger.tag(' '.join([prev_word, word, next_word]))[1][1]\n",
    "        }\n",
    "        return features\n",
    "    \n",
    "    def ner_recognize(self, sent):\n",
    "        sent = sent.strip(string.punctuation)\n",
    "        tokens = tokenize_words(sent)\n",
    "        feats = []\n",
    "        for (i, t) in enumerate(tokens):\n",
    "            if i == 0:\n",
    "                prev_word = '.'\n",
    "            else:\n",
    "                prev_word = tokens[i-1]\n",
    "            if i == len(tokens)-1:\n",
    "                next_word = '.'\n",
    "            else:\n",
    "                next_word = tokens[i+1]\n",
    "            feats.append(self._get_ner_features(t, prev_word, next_word))\n",
    "        labels = self.ner_model.predict(feats)\n",
    "        return list(zip(tokens, labels))\n",
    "    \n",
    "    def get_entity(self, q):\n",
    "        all_ents = self.obj_dict.keys()\n",
    "        parsed = self.ner_recognize(q)\n",
    "        entities = [e[0] for e in parsed if e[1] == 'LOC']\n",
    "        if not entities:\n",
    "            return self.get_entity_pymorphy(q)\n",
    "        match = get_matches(entities[0], all_ents)\n",
    "        if not match:\n",
    "            print(\"Не вдалось знайти географічний об'єкт!\")\n",
    "            print(ent)\n",
    "            return None\n",
    "        return match\n",
    "    \n",
    "    def parse_question(self, q):\n",
    "        ent = self.get_entity(q)\n",
    "        if not ent:\n",
    "            print(\"Не вдалось знайти географічний об'єкт!\")\n",
    "            return None\n",
    "        lem_sent = lemmatize_phrase(q)\n",
    "        lem_ent = lemmatize_phrase(ent)\n",
    "        new_sent = lem_sent.replace(lem_ent, '').replace('  ', ' ')\n",
    "        new_sent = new_sent.replace('який', '')\n",
    "        return ent, new_sent.strip()\n",
    "    \n",
    "    def get_features(self, q):\n",
    "        try:\n",
    "            ent, sent = self.parse_question(q)\n",
    "        except:\n",
    "            return None\n",
    "        if self.model_name == 'perceptron':\n",
    "            return self.get_features_perc(ent, sent)\n",
    "        elif self.model_name == 'logistic':\n",
    "            return self.get_features_sklearn(ent, sent)\n",
    "    \n",
    "    def get_features_perc(self, ent, sent):\n",
    "        \"\"\"\n",
    "        Given question, get features from it.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        words = fix_hyphens(tokenize_words(sent))\n",
    "        for i, w in enumerate(words):\n",
    "            features['word_{i}={w}'.format(i=i, w=w)] = 1\n",
    "        features['words'] = [('w={w}'.format(w=w), 1) for w in words]\n",
    "        bigrams = ['_'.join(b) for b in nltk.bigrams(words)]\n",
    "        features['bigrams'] = [('bg={bg}'.format(bg=bg), 1) for bg in bigrams]\n",
    "        n = 3\n",
    "        char_trigrams = [sent[i:i+n] for i in range(len(sent)-n+1)]\n",
    "        features['trigrams'] = [('t={t}'.format(t=t), 1) for t in char_trigrams]\n",
    "        return ent, features\n",
    "    \n",
    "    def get_features_sklearn(self, ent, sent):\n",
    "        features = dict()\n",
    "        words = fix_hyphens(tokenize_words(sent))\n",
    "        bigrams = ['_'.join(b) for b in nltk.bigrams(words)]\n",
    "        n = 3\n",
    "        char_trigrams = [sent[i:i+n] for i in range(len(sent)-n+1)]\n",
    "        for w in words:\n",
    "            features[w] = 1\n",
    "        for b in bigrams:\n",
    "            features[b] = 1\n",
    "        for c in char_trigrams:\n",
    "            features[c] = 1\n",
    "        return ent, features\n",
    "    \n",
    "    def train(self, train_df, n_iter=5):\n",
    "        if self.model_name == 'perceptron':\n",
    "            self.train_perc(train_df, n_iter)\n",
    "        elif self.model_name == 'logistic':\n",
    "            self.train_sklearn(train_df)\n",
    "    \n",
    "    def train_sklearn(self, train_df):\n",
    "        features = []\n",
    "        labels = []\n",
    "        for i, row in train_df.iterrows():\n",
    "            q = row['Q']\n",
    "            k = row['K']\n",
    "            try:\n",
    "                ent, feats = self.get_features(q)\n",
    "            except:\n",
    "                continue\n",
    "            if ent not in self.obj_dict:\n",
    "                print('Cannot find an entity in a dictionary for', q)\n",
    "                print(ent)\n",
    "            labels.append(k)\n",
    "            features.append(feats)\n",
    "        model = Pipeline([\n",
    "                    ('vec', DictVectorizer()),\n",
    "                    ('clf', LogisticRegression(penalty='l1'))\n",
    "        ])\n",
    "        model.fit(features, labels)\n",
    "        joblib.dump(model, 'qa_skl_model.pkl')\n",
    "        self.qa_model = model\n",
    "    \n",
    "    def train_perc(self, train_df, n_iter=5):\n",
    "        \"\"\"\n",
    "        train_df contains columns Q and A\n",
    "        \"\"\"\n",
    "        self.qa_model.classes = self.classes\n",
    "        for iteration in range(n_iter):\n",
    "            print('Training iteration number', iteration+1)\n",
    "            train_df = train_df.sample(len(train_df))\n",
    "            for i, row in train_df.iterrows():\n",
    "                q = row['Q']\n",
    "                k = row['K']\n",
    "                true_keys = []\n",
    "                try:\n",
    "                    ent, feats = self.get_features(q)\n",
    "                except:\n",
    "                    continue\n",
    "                if ent not in self.obj_dict:\n",
    "                    print('Cannot find an entity in a dictionary for', q)\n",
    "                    print(ent)\n",
    "                guess = self.qa_model.predict(feats)\n",
    "                self.qa_model.update(k, guess, feats)\n",
    "        self.qa_model.average_weights()\n",
    "        self.qa_model.save('qa_model.pkl')\n",
    "    \n",
    "    def provide_gen_case(self, ent):\n",
    "        if 'Назва в родовому відмінку' in self.obj_dict[ent].keys():\n",
    "            if not 'нема інформації' in self.obj_dict[ent]['Назва в родовому відмінку']:\n",
    "                return self.obj_dict[ent]['Назва в родовому відмінку']\n",
    "        if len(ent.split()) == 1:\n",
    "            w_parsed = morph.parse(ent)[0]\n",
    "            return w_parsed.inflect({'gent'}).word.title()\n",
    "        else:\n",
    "            res = ''\n",
    "            for w in ent.split():\n",
    "                w_parsed = morph.parse(w)[0]\n",
    "                gender = w_parsed.tag.gender\n",
    "                if not gender:\n",
    "                    res += w\n",
    "                else:\n",
    "                    res += w_parsed.inflect({gender, 'gent'}).word\n",
    "            return res\n",
    "    \n",
    "    def answer_text(self, ent, pred_class):\n",
    "        answer_template = '{pred} {ent} - {a} {units}'\n",
    "        gen_name = self.provide_gen_case(ent)\n",
    "        a = self.obj_dict[ent][pred_class]\n",
    "        units = self.unit_dict.get(pred_class)\n",
    "        if a == '' or ('нема інформації' in a):\n",
    "            units = ''\n",
    "        if not units:\n",
    "            units = ''\n",
    "        res = answer_template.format(pred=pred_class, \n",
    "                                     ent=gen_name,\n",
    "                                     a=a,\n",
    "                                     units=units).strip()\n",
    "        return res\n",
    "    \n",
    "    def find_answer(self, q):\n",
    "        try:\n",
    "            ent, feats = self.get_features(q)\n",
    "        except:\n",
    "            return 'Відповідь не знайшлась.'\n",
    "        if self.model_name == 'perceptron':\n",
    "            all_classes = self.qa_model.get_scores(feats)\n",
    "            pred_classes = self.qa_model.get_scored_classes(feats)\n",
    "            for cl in pred_classes:\n",
    "                if cl in self.obj_dict[ent] and cl in all_classes:\n",
    "                    pred_class = cl\n",
    "                    return self.answer_text(ent, pred_class)\n",
    "        elif self.model_name == 'logistic':\n",
    "            pred_class = self.qa_model.predict([feats])[0]\n",
    "            if pred_class in self.obj_dict[ent]:\n",
    "                return self.answer_text(ent, pred_class)\n",
    "        return 'Відповідь не знайшлась.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QuestionParser(obj_dict, model='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent, feats = qp.get_features_sklearn('у якому році відбулась хрещення Польщі')\n",
    "results = qp.qa_model.predict_proba([feats])[0]\n",
    "#prob_per_class_dictionary = dict(zip(qp.qa_model.classes_, results[0]))\n",
    "results_ordered_by_probability = list(map(lambda x: x[0], sorted(zip(qp.qa_model.classes_, results), key=lambda x: x[1], reverse=True)))\n",
    "#results_ordered_by_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Відповідь не знайшлась.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp.find_answer('де знаходиться Гватемала')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_questions.txt', 'r') as f:\n",
    "    tq = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "яка площа Мексики\n",
      "Площа Мексики - 1972550\n",
      "---\n",
      "---\n",
      "яка площа території Португалії\n",
      "Площа Португалії - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка територія Гвінеї\n",
      "Площа Гвінеї - 245.857\n",
      "---\n",
      "---\n",
      "який розмір Гвінеї\n",
      "Площа Гвінеї - 245.857\n",
      "---\n",
      "---\n",
      "яка столиця Мексики\n",
      "Столиця Мексики - Мехіко\n",
      "---\n",
      "---\n",
      "яке місто є столиця Мексики\n",
      "Столиця Мексики - Мехіко\n",
      "---\n",
      "---\n",
      "яка офіційна мова Австралії\n",
      "Офіційні мови Австралії - Англійська мова (англійська1)\n",
      "---\n",
      "---\n",
      "яка мова визнана в Мексиці офіційною?\n",
      "Офіційні мови Мексики - іспанська мова\n",
      "---\n",
      "---\n",
      "яка форма правління Мексики\n",
      "Форма правління Мексики - Федеративна республіка\n",
      "---\n",
      "---\n",
      "хто є президентом України\n",
      "Імена лідерів України - Порошенко Петро Олексійович, Гройсман Володимир Борисович, Парубій Андрій Володимирович\n",
      "---\n",
      "---\n",
      "хто польский президент?\n",
      "Не вдалось знайти географічний об'єкт!\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "коли відбулося хрещення Гвінеї\n",
      "Ключові дати в історії Гвінеї - 2 жовтня 1958\n",
      "---\n",
      "---\n",
      "у якому році відбулось хрещення Гвінеї\n",
      "Індекс розвитку (HDI) Гвінеї -  0.445\n",
      "---\n",
      "---\n",
      "яка чисельність населення Гвінеї\n",
      "Населення Гвінеї - 9.402.000\n",
      "---\n",
      "---\n",
      "скільки людей проживає в України\n",
      "Населення України -   (наявне населення, без урахування тимчасово окупованої території Автономної Республіки Крим і м. Севастополя)\n",
      "---\n",
      "---\n",
      "яка густота населення Австралії\n",
      "Густота населення Австралії - 2.8\n",
      "---\n",
      "---\n",
      "який ВВП на душу населення у Гвінеї\n",
      "ВВП (ПКС) на душу населення Гвінеї - $2,035\n",
      "---\n",
      "---\n",
      "який повний ВВП Ботсвани\n",
      "ВВП (ПКС) Ботсвани - $18.72 млрд.\n",
      "---\n",
      "---\n",
      "яка валюта Ботсвани\n",
      "Валюта Ботсвани - Ботсванська пула (Пула)\n",
      "---\n",
      "---\n",
      "як називається валюта, яку використовують у Португалії\n",
      "Валюта Португалії - Євро\n",
      "---\n",
      "---\n",
      "який часовий пояс Мексики\n",
      "Часовий пояс Мексики - нема інформації в базі\n",
      "---\n",
      "---\n",
      "який домен України\n",
      "Інтернет-домен України - .ua, .укр\n",
      "---\n",
      "---\n",
      "який телефонний код Ботсвани\n",
      "Телефонний код Ботсвани - 267\n",
      "---\n",
      "---\n",
      "які офіційні мови Гвінеї\n",
      "Офіційні мови Гвінеї - Французька мова (Французька)\n",
      "---\n",
      "---\n",
      "чи належить німецька до офіційних мов Австралії\n",
      "Ключові дати в історії Австралії - 1 січня 1901, 11 грудня 1931, 3 березня 1986\n",
      "---\n",
      "---\n",
      "столицею якої країни є Тегусігальпа\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "в якому регіоні розміщена Вінниця\n",
      "Площа Вінниці - 113.2\n",
      "---\n",
      "---\n",
      "який девіз Вінниці\n",
      "Площа Вінниці - 113.2\n",
      "---\n",
      "---\n",
      "коли було засновано Вінницю\n",
      "Ключові дати в історії Вінниці - нема інформації в базі\n",
      "---\n",
      "---\n",
      "у якому столітті було засновано Париж\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яке населення Сакраменто\n",
      "Населення Сакраменто - 2.149.127\n",
      "---\n",
      "---\n",
      "скільки людей живе у Пекіні\n",
      "Населення Пекіна - нема інформації в базі\n",
      "---\n",
      "---\n",
      "скільки людей мешкає у Римі\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "скільки людей проживає в агломерації Пекіну?\n",
      "Населення Пекіна - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка площа Вінниці\n",
      "Площа Вінниці - 113.2\n",
      "---\n",
      "---\n",
      "який розмір Сакраменто\n",
      "Площа Сакраменто - 259\n",
      "---\n",
      "---\n",
      "яка площа території Сакраменто\n",
      "Площа Сакраменто - 259\n",
      "---\n",
      "---\n",
      "яка густота населення Монтевідео\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які поштові індекси Риму\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який телефонний код Монтевідео\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який часовий пояс Вінниці\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які номери автомобілів Вінниці\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які водойми є у Пекіні\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "скільки районів є у Монтевідео\n",
      "Населення Монтевідео - 1,325,968 (2004)\n",
      "---\n",
      "---\n",
      "який поділ міста Тегусігальпа\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які міста-побратими є у Пекіна\n",
      "Назва державною мовою Пекіна - нема інформації в базі\n",
      "---\n",
      "---\n",
      "хто є мером Парижа\n",
      "Імена лідерів Парижа - нема інформації в базі\n",
      "---\n",
      "---\n",
      "як звуть мера Пекіна\n",
      "Імена лідерів Пекіна - Ван Аньшунь 王安顺\n",
      "---\n",
      "---\n",
      "яка веб-сторінка Тегусігальпа\n",
      "Площа Тегусігальпа - нема інформації в базі\n",
      "---\n",
      "---\n",
      "де розташоване Китайське море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "в якій частині світу розташоване Середземне море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка довжина Чорного моря?\n",
      "Інтернет-домен Чорногорії - .me\n",
      "---\n",
      "---\n",
      "наскільки довге Арабське море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка площа Жовтого моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яку територію займає Жовте море?\n",
      "Населення Нового - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка найбільша глибина Жовтого моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "наскільки глибоке Середземне море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка глибина найглибшої точки Китайського моря?\n",
      "Густота населення Батайська - нема інформації в базі\n",
      "---\n",
      "---\n",
      "як глибоко знайходиться найглибша точка Чорного моря?\n",
      "Інтернет-домен Чорногорії - .me\n",
      "---\n",
      "---\n",
      "яка середня глибина Середземного моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який об'єм Арабського моря?\n",
      "Площа Барабінська - нема інформації в базі\n",
      "---\n",
      "---\n",
      "який об'єм займає Жовте море?\n",
      "Населення Нового - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка ширина Середземного моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "наскільки широке Китайське море?\n",
      "Площа Батайська - 77.68\n",
      "---\n",
      "---\n",
      "звідки витікає Дніпро\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "де розміщений витік Рейну\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які координати витоку Меконга\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка широта витоку Рейну\n",
      "Площа Рені - 39.3\n",
      "---\n",
      "---\n",
      "яка довгота витоку Рони\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка висота витоку Меконга\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "що є гирлом Амазонки\n",
      "Площа Амазонасу - 1570947\n",
      "---\n",
      "---\n",
      "де знаходиться гирло Дніпра\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які координати гирла Конго\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка широта гирла Хуанхе\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-635cd85d58d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-6ce1c44fad06>\u001b[0m in \u001b[0;36mfind_answer\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqa_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpred_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'Відповідь не знайшлась.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-6ce1c44fad06>\u001b[0m in \u001b[0;36manswer_text\u001b[0;34m(self, ent, pred_class, units)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manswer_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0manswer_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{pred} {ent} - {a} {units}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mgen_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovide_gen_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-6ce1c44fad06>\u001b[0m in \u001b[0;36mprovide_gen_case\u001b[0;34m(self, ent)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mw_parsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mw_parsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'gent'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'word'"
     ]
    }
   ],
   "source": [
    "for q_text in tq:\n",
    "    print('---')\n",
    "    print(q_text)\n",
    "    print(qp.find_answer(q_text))\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
