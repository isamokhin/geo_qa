{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "from ukr_stemmer3 import UkrainianStemmer\n",
    "from tokenize_uk import tokenize_words, tokenize_sents\n",
    "from models.tagger import PerceptronTagger # POS tagger\n",
    "from models.qa_perceptron import AveragedPerceptron # model for parsing question\n",
    "from sklearn.externals import joblib\n",
    "from difflib import get_close_matches\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cleaned data from saved dictionaries\n",
    "with open('data/obj_dict.pkl', 'rb') as f:\n",
    "    obj_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_phrase(phrase):\n",
    "    \"\"\"\n",
    "    Also we can stem instead of lemmatizing...\n",
    "    \"\"\"\n",
    "    words = fix_hyphens(tokenize_words(phrase))\n",
    "    if len(words) == 1:\n",
    "        wparsed = morph.parse(phrase)[0]\n",
    "        if not wparsed:\n",
    "            return phrase\n",
    "        return wparsed.normal_form\n",
    "    else:\n",
    "        new_phrase = ''\n",
    "        for w in words:\n",
    "            new_phrase += morph.parse(w)[0].normal_form + ' '\n",
    "        return new_phrase.strip()\n",
    "\n",
    "def lemmatize_ent(ent):\n",
    "    wparsed = morph.parse(ent)[0]\n",
    "    if not wparsed:\n",
    "        return ent\n",
    "    if ent.istitle():\n",
    "        return wparsed.normal_form.title()\n",
    "    else:\n",
    "        return wparsed.normal_form\n",
    "    \n",
    "def fix_hyphens(sent):\n",
    "    \"\"\"\n",
    "    sent is tokenized with tokenize_uk\n",
    "    \"\"\"\n",
    "    new_sent = []\n",
    "    i = 0\n",
    "    while i < len(sent):\n",
    "        w = sent[i]\n",
    "        if w == '—' or w == '-':\n",
    "            new_sent.pop()\n",
    "            new_word = sent[i-1]+'-'+sent[i+1]\n",
    "            new_sent.append(new_word)\n",
    "            i += 1\n",
    "        else:\n",
    "            new_sent.append(w)\n",
    "        i += 1\n",
    "    return new_sent\n",
    "\n",
    "def gender_agree(w_parsed):\n",
    "    \"\"\"\n",
    "    Inflect noun phrase with adjective the right way\n",
    "    \"\"\"\n",
    "    gender = w_parsed.tag.gender\n",
    "    if not gender:\n",
    "        return w_parsed.normal_form\n",
    "    w = w_parsed.inflect({gender, 'nomn'}).word\n",
    "    return w\n",
    "    \n",
    "def get_matches(ent, all_ents):\n",
    "    matches = get_close_matches(ent, all_ents)\n",
    "    if not matches:\n",
    "        for entry in all_ents:\n",
    "            if ent.lower() in entry.lower():\n",
    "                return entry\n",
    "    return matches[0]\n",
    "\n",
    "def deparentize(k):\n",
    "    res = re.sub(r'\\(.*\\)', '', k)\n",
    "    res = re.sub(r'\\[.*\\]', '', res).strip()\n",
    "    return res\n",
    "\n",
    "def ent_phrase(ner_recognized):\n",
    "    \"\"\"\n",
    "    ner_recognized is a list of tokens and labels.\n",
    "    \"\"\"\n",
    "    ent_phrases = []\n",
    "    current_phrase = ''\n",
    "    for token, label in ner_recognized:\n",
    "        if label == 'LOC':\n",
    "            current_phrase += lemmatize_ent(token) + ' '\n",
    "        elif (len(current_phrase) > 0) and label != 'LOC':\n",
    "            ent_phrases.append(current_phrase.strip())\n",
    "            current_phrase = ''\n",
    "        else:\n",
    "            continue\n",
    "    ent_phrases.append(current_phrase.strip())\n",
    "    if not [e for e in ent_phrases if e != '']:\n",
    "        return None\n",
    "    return ent_phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionParser():\n",
    "    \n",
    "    def __init__(self, model = 'perceptron'):\n",
    "        self.model_name = model\n",
    "        self.pos_tagger = PerceptronTagger()\n",
    "        try:\n",
    "            with open('data/obj_dict.pkl', 'rb') as od:\n",
    "                self.obj_dict = pickle.load(od)\n",
    "            with open('data/units.pkl', 'rb') as ud:\n",
    "                self.unit_dict = pickle.load(ud)\n",
    "            self.ner_model = joblib.load('models/NER_model.pkl')\n",
    "            if model == 'perceptron':\n",
    "                self.qa_model = AveragedPerceptron()\n",
    "                self.load_perc('models/qa_model.pkl')\n",
    "            elif model == 'logistic':\n",
    "                self.qa_model = joblib.load('models/qa_skl_model.pkl')\n",
    "            elif model == None:\n",
    "                print('Please train the model for QA.')\n",
    "        except:\n",
    "            print('Будь ласка, переконайтесь, що в директорії models є всі потрібні файли.')\n",
    "            print('Без них програма не працюватиме.')\n",
    "        self.lem_dict = [morph.parse(ent.split()[0])[0].normal_form \n",
    "                         for ent in self.obj_dict.keys()]\n",
    "        self.disamb_dict = self.build_disamb_dict()\n",
    "    \n",
    "    def load_perc(self, loc):\n",
    "        weights, classes = pickle.load(open(loc, 'rb'))\n",
    "        self.qa_model.weights = weights\n",
    "        self.qa_model.classes = classes\n",
    "        return None\n",
    "    \n",
    "    def build_disamb_dict(self):\n",
    "        from collections import Counter\n",
    "        depar_keys = [deparentize(k) for k in self.obj_dict]\n",
    "        disamb_dict = dict()\n",
    "        duplicates = [item for item, count in Counter(depar_keys).items() if count > 1]\n",
    "        for k in depar_keys:\n",
    "            disamb_dict[k] = []\n",
    "        for k in self.obj_dict:\n",
    "            disamb_dict[deparentize(k)].append(k)\n",
    "        return disamb_dict\n",
    "    \n",
    "    def get_entity_pymorphy(self, q_text):\n",
    "        \"\"\"\n",
    "        Look for (capitalized) entities in q_text.\n",
    "        For this specific application pymorphy2 tagging is enough.\n",
    "        \"\"\"\n",
    "        forbidden = ['ВВП', 'HDI', 'ISO', 'ООН', 'UN', 'UTC', \n",
    "                     'Utc-Поправка', 'Utc-Поправка']\n",
    "        words = fix_hyphens(tokenize_words(q_text))\n",
    "        phrase = []\n",
    "        for i, w in enumerate(words[1:]):\n",
    "            if w in forbidden:\n",
    "                continue\n",
    "            if w[0] == w[0].upper():\n",
    "                w_parsed = morph.parse(w.strip(' ?'))[0]\n",
    "                w_lemma = w_parsed.normal_form\n",
    "                if w_lemma in self.lem_dict:\n",
    "                    if 'ADJF' in w_parsed.tag:\n",
    "                        phrase.append(gender_agree(w_parsed).title())\n",
    "                        phrase.append(morph.parse\n",
    "                                      (words[i+2].strip(' ?'))[0].normal_form)\n",
    "                        return ' '.join(phrase).title()\n",
    "                    elif 'NOUN' in w_parsed.tag:\n",
    "                        return w_lemma.title()\n",
    "                    elif 'UNKN' in w_parsed.tag:\n",
    "                        return w_lemma.title()\n",
    "                matches = get_close_matches(w_lemma.title(), list(self.disamb_dict.keys()))\n",
    "                if matches:\n",
    "                    return matches[0]\n",
    "                else:\n",
    "                    continue\n",
    "        return None\n",
    "    \n",
    "    def _get_ner_features(self, word, prev_word, next_word):\n",
    "        features = {\n",
    "            'word': word,\n",
    "            'word_stem': UkrainianStemmer(word).stem_word(),\n",
    "            'prev_word': prev_word,\n",
    "            'next_word': next_word,\n",
    "            'prev_stem': UkrainianStemmer(prev_word).stem_word(),\n",
    "            'next_stem': UkrainianStemmer(next_word).stem_word(),\n",
    "            'is_uppercase': word.title() == word,\n",
    "            'is_after_punct': prev_word in string.punctuation,\n",
    "            'is_after_uppercase': prev_word.title() == prev_word,\n",
    "            'pos': self.pos_tagger.tag(' '.join([prev_word, word, next_word]))[1][1]\n",
    "        }\n",
    "        return features\n",
    "    \n",
    "    def ner_recognize(self, sent):\n",
    "        sent = sent.strip(string.punctuation)\n",
    "        tokens = fix_hyphens(tokenize_words(sent))\n",
    "        feats = []\n",
    "        for (i, t) in enumerate(tokens):\n",
    "            if i == 0:\n",
    "                prev_word = '.'\n",
    "            else:\n",
    "                prev_word = tokens[i-1]\n",
    "            if i == len(tokens)-1:\n",
    "                next_word = '.'\n",
    "            else:\n",
    "                next_word = tokens[i+1]\n",
    "            feats.append(self._get_ner_features(t, prev_word, next_word))\n",
    "        labels = self.ner_model.predict(feats)\n",
    "        first_res = list(zip(tokens, labels))\n",
    "        res = []\n",
    "        for token, label in first_res:\n",
    "            if token in ['море', \"моря\", \"озеро\", \"озера\", \"океан\", \"океану\"]:\n",
    "                res.append((token, 'LOC'))\n",
    "            else:\n",
    "                res.append((token, label))\n",
    "        return res\n",
    "    \n",
    "    def get_entity(self, q):\n",
    "        all_ents = self.disamb_dict.keys()\n",
    "        ner_recognized = self.ner_recognize(q)\n",
    "        to_match = ent_phrase(ner_recognized)\n",
    "        if not to_match:\n",
    "            return self.get_entity_pymorphy(q)\n",
    "        match = get_matches(to_match, all_ents)\n",
    "        if not match:\n",
    "            print(\"Не вдалось знайти географічний об'єкт\", q)\n",
    "            return None\n",
    "        return match\n",
    "    \n",
    "    def parse_question(self, q):\n",
    "        ent = self.get_entity(q)\n",
    "        if not ent:\n",
    "            print(\"Не вдалось знайти географічний об'єкт!\", q)\n",
    "            return None, None\n",
    "        lem_sent = lemmatize_phrase(q)\n",
    "        lem_ent = lemmatize_phrase(ent)\n",
    "        new_sent = lem_sent.replace(lem_ent, '').replace('  ', ' ')\n",
    "        new_sent = new_sent.replace('який', '')\n",
    "        return ent, new_sent.strip()\n",
    "    \n",
    "    def get_features(self, q):\n",
    "        try:\n",
    "            ent, sent = self.parse_question(q)\n",
    "        except:\n",
    "            return None\n",
    "        if not ent:\n",
    "            return None\n",
    "        if self.model_name == 'perceptron':\n",
    "            return self.get_features_perc(ent, sent)\n",
    "        elif self.model_name == 'logistic':\n",
    "            return self.get_features_sklearn(ent, sent)\n",
    "    \n",
    "    def get_features_perc(self, ent, sent):\n",
    "        \"\"\"\n",
    "        Given question, get features from it.\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        words = fix_hyphens(tokenize_words(sent))\n",
    "        for i, w in enumerate(words):\n",
    "            features['word_{i}={w}'.format(i=i, w=w)] = 1\n",
    "        features['words'] = [('w={w}'.format(w=w), 1) for w in words]\n",
    "        bigrams = ['_'.join(b) for b in nltk.bigrams(words)]\n",
    "        features['bigrams'] = [('bg={bg}'.format(bg=bg), 1) for bg in bigrams]\n",
    "        n = 3\n",
    "        char_trigrams = [sent[i:i+n] for i in range(len(sent)-n+1)]\n",
    "        features['trigrams'] = [('t={t}'.format(t=t), 1) for t in char_trigrams]\n",
    "        return ent, features\n",
    "    \n",
    "    def get_features_sklearn(self, ent, sent):\n",
    "        features = dict()\n",
    "        words = fix_hyphens(tokenize_words(sent))\n",
    "        bigrams = ['_'.join(b) for b in nltk.bigrams(words)]\n",
    "        n = 3\n",
    "        char_trigrams = [sent[i:i+n] for i in range(len(sent)-n+1)]\n",
    "        for w in words:\n",
    "            features[w] = 1\n",
    "        for b in bigrams:\n",
    "            features[b] = 1\n",
    "        for c in char_trigrams:\n",
    "            features[c] = 1\n",
    "        return ent, features\n",
    "    \n",
    "    def train(self, train_df, n_iter=5):\n",
    "        if self.model_name == 'perceptron':\n",
    "            self.train_perc(train_df, n_iter)\n",
    "        elif self.model_name == 'logistic':\n",
    "            self.train_sklearn(train_df)\n",
    "    \n",
    "    def train_sklearn(self, train_df):\n",
    "        features = []\n",
    "        labels = []\n",
    "        for i, row in train_df.iterrows():\n",
    "            q = row['Q']\n",
    "            k = row['K']\n",
    "            try:\n",
    "                ent, feats = self.get_features(q)\n",
    "            except:\n",
    "                continue\n",
    "            labels.append(k)\n",
    "            features.append(feats)\n",
    "        model = Pipeline([\n",
    "                    ('vec', DictVectorizer()),\n",
    "                    ('clf', LogisticRegression(penalty='l1'))\n",
    "        ])\n",
    "        model.fit(features, labels)\n",
    "        joblib.dump(model, 'models/qa_skl_model.pkl')\n",
    "        self.qa_model = model\n",
    "    \n",
    "    def train_perc(self, train_df, n_iter=5):\n",
    "        \"\"\"\n",
    "        train_df contains columns Q and A\n",
    "        \"\"\"\n",
    "        allkeys = []\n",
    "        for c in obj_dict:\n",
    "            for k in obj_dict[c]:\n",
    "                allkeys.append(k)\n",
    "        allkeys = set(allkeys)\n",
    "        self.qa_model.classes = allkeys\n",
    "        for iteration in range(n_iter):\n",
    "            print('Training iteration number', iteration+1)\n",
    "            train_df = train_df.sample(len(train_df))\n",
    "            for i, row in train_df.iterrows():\n",
    "                q = row['Q']\n",
    "                k = row['K']\n",
    "                true_keys = []\n",
    "                try:\n",
    "                    ent, feats = self.get_features(q)\n",
    "                except:\n",
    "                    continue\n",
    "                guess = self.qa_model.predict(feats)\n",
    "                self.qa_model.update(k, guess, feats)\n",
    "        self.qa_model.average_weights()\n",
    "        self.qa_model.save('models/qa_model.pkl')\n",
    "    \n",
    "    def provide_gen_case(self, ent):\n",
    "        if 'Назва в родовому відмінку' in self.obj_dict[ent].keys():\n",
    "            if not 'нема інформації' in self.obj_dict[ent]['Назва в родовому відмінку']:\n",
    "                return self.obj_dict[ent]['Назва в родовому відмінку']\n",
    "        ent = deparentize(ent)\n",
    "        if len(ent.split()) == 1:\n",
    "            w_parsed = morph.parse(ent)[0]\n",
    "            return w_parsed.inflect({'gent'}).word.title()\n",
    "        else:\n",
    "            res = ''\n",
    "            for w in ent.split():\n",
    "                w_parsed = morph.parse(w)[0]\n",
    "                gender = w_parsed.tag.gender\n",
    "                if not gender:\n",
    "                    res += w\n",
    "                elif w.startswith('мор'):\n",
    "                    res += 'моря'\n",
    "                else:\n",
    "                    res += w_parsed.inflect({gender, 'gent'}).word + ' '\n",
    "            res = res[0].upper() + res[1:]\n",
    "            return res.strip()\n",
    "    \n",
    "    def answer_text(self, answers):\n",
    "        answer_template = '{pred} {ent} - {a} {units}'\n",
    "        answer_texts = []\n",
    "        for ent, cl, a in answers:\n",
    "            a = str(a)\n",
    "            detail = ''\n",
    "            if len(answers) > 1:\n",
    "                if 'уточнення' in self.obj_dict[ent]:\n",
    "                    detail += '{0}, '.format(self.obj_dict[ent]['уточнення'])\n",
    "                if '[' in ent:\n",
    "                    detail += re.search(r'\\[(.*)\\]', ent).group(1)\n",
    "                detail = '('+detail.strip(' ,')+')'\n",
    "            gen_name = self.provide_gen_case(ent) + ' ' + detail\n",
    "            gen_name = gen_name.strip()\n",
    "            units = self.unit_dict.get(cl)\n",
    "            if a == '' or ('нема інформації' in a):\n",
    "                units = ''\n",
    "            if not units:\n",
    "                units = ''\n",
    "            res = answer_template.format(pred=cl, \n",
    "                                         ent=gen_name,\n",
    "                                         a=a,\n",
    "                                         units=units).strip()\n",
    "            answer_texts.append(res)\n",
    "        if len(answer_texts) > 1:\n",
    "            a_text = '\\n'.join(answer_texts)\n",
    "        else:\n",
    "            a_text = answer_texts[0]\n",
    "        return a_text\n",
    "    \n",
    "    def find_answers(self, ent, pred_classes):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        answers = []\n",
    "        candidates = self.disamb_dict[ent]\n",
    "        for c in candidates:\n",
    "            for cl in pred_classes:\n",
    "                a = self.obj_dict[c].get(cl)\n",
    "                if a:\n",
    "                    answers.append((c, cl, a))\n",
    "                    break\n",
    "        return answers\n",
    "    \n",
    "    def answer_the_question(self, q):\n",
    "        q = q.replace('ґ', \"г\")\n",
    "        try:\n",
    "            ent, feats = self.get_features(q)\n",
    "        except:\n",
    "            return 'Відповідь не знайшлась.'\n",
    "        if not ent:\n",
    "            return 'Відповідь не знайшлась.'\n",
    "        if self.model_name == 'perceptron':\n",
    "            pred_classes = self.qa_model.get_scored_classes(feats)[:3]\n",
    "        elif self.model_name == 'logistic':\n",
    "            pred_probs = qp.qa_model.predict_proba([feats])[0]\n",
    "            prob_per_class = dict(zip(self.qa_model.classes_, pred_probs))\n",
    "            cl_by_prob = list(map(lambda x: x[0], \n",
    "                                  sorted(zip(self.qa_model.classes_, prob_per_class), \n",
    "                                         key=lambda x: x[1], reverse=True)))\n",
    "            pred_classes = cl_by_prob[:3]\n",
    "        answers = self.find_answers(ent, pred_classes)\n",
    "        if not answers:\n",
    "            return 'Відповідь не знайшлась.'\n",
    "        return self.answer_text(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QuestionParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не вдалось знайти географічний об'єкт! хто польский президент\n"
     ]
    }
   ],
   "source": [
    "qp.get_features('хто польский президент')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent, feats = qp.get_features('яка площа басейну Рейна?')\n",
    "pred_probs = qp.qa_model.predict_proba([feats])[0]\n",
    "#answers = qp.find_answers(ent, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Площа басейну Рейну - 185000 км²'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp.answer_the_question('яка площа басейну Рейна')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('яка', '-'), ('площа', '-'), ('Лос-Анджелесу', 'LOC')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent, feats = qp.get_features('яка площа Лос-Анджелесу')\n",
    "qp.ner_recognize('яка площа Лос-Анджелесу')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_questions.txt', 'r') as f:\n",
    "    tq = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5118110236220472"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65/(len(tq)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "яка площа Мексики\n",
      "Площа Мексики - 1972550 км²\n",
      "---\n",
      "---\n",
      "яка площа території Португалії\n",
      "Площа Португалії - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка територія Гвінеї\n",
      "Площа Гвінеї - 245.857 км²\n",
      "---\n",
      "---\n",
      "який розмір Гвінеї\n",
      "Площа Гвінеї - 245.857 км²\n",
      "---\n",
      "---\n",
      "яка столиця Мексики\n",
      "Столиця Мексики - Мехіко\n",
      "---\n",
      "---\n",
      "яке місто є столиця Мексики\n",
      "Столиця Мексики - Мехіко\n",
      "---\n",
      "---\n",
      "яка офіційна мова Австралії\n",
      "Офіційні мови Австралії - Англійська мова (англійська1)\n",
      "---\n",
      "---\n",
      "яка мова визнана в Мексиці офіційною?\n",
      "Офіційні мови Мексики - іспанська мова\n",
      "---\n",
      "---\n",
      "яка форма правління Мексики\n",
      "Форма правління Мексики - Федеративна республіка\n",
      "---\n",
      "---\n",
      "хто є президентом України\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "хто польский президент?\n",
      "Не вдалось знайти географічний об'єкт! хто польский президент?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "коли відбулося хрещення Гвінеї\n",
      "Рік останнього перепису населення Гвінеї - 1996\n",
      "---\n",
      "---\n",
      "у якому році відбулось хрещення Гвінеї\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка чисельність населення Гвінеї\n",
      "Густота населення Гвінеї - 38 осіб на км²\n",
      "---\n",
      "---\n",
      "скільки людей проживає в України\n",
      "Населення України -   (наявне населення, без урахування тимчасово окупованої території Автономної Республіки Крим і м. Севастополя) осіб\n",
      "---\n",
      "---\n",
      "яка густота населення Австралії\n",
      "Густота населення Австралії - 2.8 осіб на км²\n",
      "---\n",
      "---\n",
      "який ВВП на душу населення у Гвінеї\n",
      "ВВП (ПКС) на душу населення Гвінеї - $2,035  доларів\n",
      "---\n",
      "---\n",
      "який повний ВВП Ботсвани\n",
      "ВВП (ПКС) Ботсвани - $18.72 млрд. доларів\n",
      "---\n",
      "---\n",
      "яка валюта Ботсвани\n",
      "Валюта Ботсвани - Ботсванська пула (Пула)\n",
      "---\n",
      "---\n",
      "як називається валюта, яку використовують у Португалії\n",
      "Валюта Португалії - Євро\n",
      "---\n",
      "---\n",
      "який часовий пояс Мексики\n",
      "Часовий пояс Мексики - нема інформації в базі\n",
      "---\n",
      "---\n",
      "який домен України\n",
      "Інтернет-домен України - .ua, .укр\n",
      "---\n",
      "---\n",
      "який телефонний код Ботсвани\n",
      "Телефонний код Ботсвани - 267\n",
      "---\n",
      "---\n",
      "які офіційні мови Гвінеї\n",
      "Офіційні мови Гвінеї - Французька мова (Французька)\n",
      "---\n",
      "---\n",
      "чи належить німецька до офіційних мов Австралії\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "столицею якої країни є Тегусігальпа\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "в якому регіоні розміщена Вінниця\n",
      "Регіон Вінниці - Вінницька область\n",
      "---\n",
      "---\n",
      "який девіз Вінниці\n",
      "Девіз Вінниці - нема інформації в базі\n",
      "---\n",
      "---\n",
      "коли було засновано Вінницю\n",
      "Засноване Вінниці - 1355\n",
      "---\n",
      "---\n",
      "у якому столітті було засновано Париж\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яке населення Сакраменто\n",
      "Населення Сакраменто - 2.149.127 осіб\n",
      "---\n",
      "---\n",
      "скільки людей живе у Пекіні\n",
      "Населення Пекіна - нема інформації в базі\n",
      "---\n",
      "---\n",
      "скільки людей мешкає у Римі\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "скільки людей проживає в агломерації Пекіну?\n",
      "Населення Пекіна - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка площа Вінниці\n",
      "Площа Вінниці - 113.2 км²\n",
      "---\n",
      "---\n",
      "який розмір Сакраменто\n",
      "Площа Сакраменто - 259 км²\n",
      "---\n",
      "---\n",
      "яка площа території Сакраменто\n",
      "Площа Сакраменто - 259 км²\n",
      "---\n",
      "---\n",
      "яка густота населення Монтевідео\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які поштові індекси Риму\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який телефонний код Монтевідео\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який часовий пояс Вінниці\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які номери автомобілів Вінниці\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які водойми є у Пекіні\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "скільки районів є у Монтевідео\n",
      "Населення Монтевідео - 1,325,968 (2004) осіб\n",
      "---\n",
      "---\n",
      "який поділ міста Тегусігальпа\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які міста-побратими є у Пекіна\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "хто є мером Парижа\n",
      "Мер Парижа - Анн Ідальго (Anne Hidalgo)\n",
      "---\n",
      "---\n",
      "як звуть мера Пекіна\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка веб-сторінка Тегусігальпа\n",
      "Веб-сторінка Тегусігальпа - нема інформації в базі\n",
      "---\n",
      "---\n",
      "де розташоване Китайське море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "в якій частині світу розташоване Середземне море?\n",
      "Розташування Середземного моря - Атлантичний океан\n",
      "---\n",
      "---\n",
      "яка довжина Чорного моря?\n",
      "Довжина берегової лінії Чорного моря - 4090 км\n",
      "---\n",
      "---\n",
      "наскільки довге Арабське море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка площа Жовтого моря?\n",
      "Площа Жовтого моря - 416000 км²\n",
      "---\n",
      "---\n",
      "яку територію займає Жовте море?\n",
      "Площа Жовтого моря - 416000 км²\n",
      "---\n",
      "---\n",
      "яка найбільша глибина Жовтого моря?\n",
      "Найбільша глибина Жовтого моря - 106 м\n",
      "---\n",
      "---\n",
      "наскільки глибоке Середземне море?\n",
      "Середня глибина Середземного моря - 1536 м\n",
      "---\n",
      "---\n",
      "яка глибина найглибшої точки Китайського моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "як глибоко знайходиться найглибша точка Чорного моря?\n",
      "Найбільша глибина Чорного моря - 2245 м\n",
      "---\n",
      "---\n",
      "яка середня глибина Середземного моря?\n",
      "Середня глибина Середземного моря - 1536 м\n",
      "---\n",
      "---\n",
      "який об'єм Арабського моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який об'єм займає Жовте море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка ширина Середземного моря?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "наскільки широке Китайське море?\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "звідки витікає Дніпро\n",
      "Розташування гирла Дніпра - нема інформації в базі\n",
      "---\n",
      "---\n",
      "де розміщений витік Рейну\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які координати витоку Меконга\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка широта витоку Рейну\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка довгота витоку Рони\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка висота витоку Меконга\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "що є гирлом Амазонки\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "де знаходиться гирло Дніпра\n",
      "Розташування гирла Дніпра - нема інформації в базі\n",
      "---\n",
      "---\n",
      "які координати гирла Конго\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка широта гирла Хуанхе\n",
      "Розташування гирла Хуанхе - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка довгота гирла Рейну\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка площа басейну Рейну\n",
      "Площа басейну Рейну - 185000 км²\n",
      "---\n",
      "---\n",
      "яку територію займає басейн Меконга\n",
      "Площа басейну Меконга - 795 000 км²\n",
      "---\n",
      "---\n",
      "скільки квадратних кілометрів займає басейн Конго\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "що є басейном Рони\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яке море є басейном Дніпра\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "через які країни протікає Хуанхе\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка довжина Конго\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "у якому регіоні тече Дніпро\n",
      "Регіон Дніпра - Дніпропетровська область\n",
      "---\n",
      "---\n",
      "як називається регіон, по якому протікає Хуанхе\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який середнорічний стік Хуанхе\n",
      "Стік Хуанхе - 2 571 м³/с\n",
      "---\n",
      "---\n",
      "який обсяг середньорічного стоку Рейну\n",
      "Стік Рейну - 2290 м³/с (на межі з Нідерландами\n",
      "---\n",
      "---\n",
      "які притоки має Хуанхе\n",
      "Притоки Хуанхе - Тао () (пр.),Фен () (л.),Ло () (пр.),Вей () (пр.)\n",
      "---\n",
      "---\n",
      "які водойми є в руслі Хуанхе\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "в якій країні розміщена Говерла\n",
      "Країна Говерли - нема інформації в базі\n",
      "---\n",
      "---\n",
      "в якому регіоні знаходиться Говерла\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "де розташований Еверест\n",
      "Розташування Евереста - Зона Сагарматха, Непал, Азія\n",
      "---\n",
      "---\n",
      "в якій системі розташована Говерла\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "частиною якої системи є Еверест\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "до якої системи належить Кіліманджаро\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "до якого типу належить Монблан\n",
      "Тип Монблану - нема інформації в базі\n",
      "---\n",
      "---\n",
      "який тип Монблан\n",
      "Тип Монблану - нема інформації в базі\n",
      "---\n",
      "---\n",
      "що таке Говерла\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "з якого матеріалу складається Еверест\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "з чого складається Монблан\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка висота Говерли\n",
      "Висота над рівнем моря Говерли - 2061 м м\n",
      "---\n",
      "---\n",
      "яка відносна висота Монблану\n",
      "Відносна висота Монблану - 4696 м(Список гір за відносною висотою (11-те місце у світі)) м\n",
      "---\n",
      "---\n",
      "наскільки висока Кіліманджаро\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "коли відбулось перше сходження на Еверест\n",
      "Перше сходження Евереста - 29 травня 1953 року\n",
      "---\n",
      "---\n",
      "у якому році було перше сходження на Кіліманджаро\n",
      "Перше сходження Кіліманджаро - нема інформації в базі\n",
      "---\n",
      "---\n",
      "у якому році людина вперше побувала на вершині Говерли\n",
      "Перше сходження Говерли - Невідомо\n",
      "---\n",
      "---\n",
      "де розташований Балатон\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які координати Байкалу\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "в якій країні розташована Тітікака\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "що таке Тітікака\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "до якого типу належить Тітікака\n",
      "Тип Тітікаки - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яким озером є Тітікака\n",
      "Тип Тітікаки - нема інформації в базі\n",
      "---\n",
      "---\n",
      "які прибережні країни Тітікаки\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які розміри Тітікаки\n",
      "Площа Тітікаки - 8372 км²\n",
      "---\n",
      "---\n",
      "яка висота над рівнем моря Гурону\n",
      "Висота над рівнем моря Гурону - 176 м м\n",
      "---\n",
      "---\n",
      "наскільки високо над рівнем моря розміщений Байкал\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "яка площа поверхні Балатона\n",
      "Площа Балатона - 594 км²\n",
      "---\n",
      "---\n",
      "яку площу займає Ківу\n",
      "Площа Ківа - 2700 км²\n",
      "---\n",
      "---\n",
      "яку територію займає Тітікака\n",
      "Площа Тітікаки - 8372 км²\n",
      "---\n",
      "---\n",
      "наскільки глибоке Балатон\n",
      "Середня глибина Балатона - 3 м\n",
      "---\n",
      "---\n",
      "яка максимальна глибина Тітікаки\n",
      "Найбільша глибина Тітікаки - нема інформації в базі\n",
      "---\n",
      "---\n",
      "яка ширина Байкалу\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "наскільки широке Байкал\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який об'єм Балатона\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "який об'єм займає Балатон\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які річки витікають з Гурону\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які міста розташовані на берегах Балатона\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "які міста знаходяться поряд з Ківу\n",
      "Відповідь не знайшлась.\n",
      "---\n",
      "---\n",
      "\n",
      "Відповідь не знайшлась.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for q_text in tq:\n",
    "    print('---')\n",
    "    print(q_text)\n",
    "    print(qp.answer_the_question(q_text))\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
