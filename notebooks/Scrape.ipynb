{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import re\n",
    "from collections import OrderedDict, Counter\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://uk.wikipedia.org/w/index.php?title=%D2%90%D1%80%D0%B5%D0%BD%D0%BB%D0%B0%D0%BD%D0%B4%D1%81%D1%8C%D0%BA%D0%B5_%D0%BC%D0%BE%D1%80%D0%B5&action=edit&section=0'\n",
    "a = 'https://uk.wikipedia.org/w/index.php?title=%D2%90%D1%80%D0%B5%D0%BD%D0%BB%D0%B0%D0%BD%D0%B4%D1%81%D1%8C%D0%BA%D0%B5_%D0%BC%D0%BE%D1%80%D0%B5&action=edit&section=0'\n",
    "r = requests.get(url)\n",
    "html = BeautifulSoup(r.content, 'lxml')\n",
    "text = re.search(r'({{.*}})', html.find('textarea').get_text(), re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card(url):\n",
    "    r = requests.get(url)\n",
    "    html = BeautifulSoup(r.content, 'lxml')\n",
    "    text = re.search(r'({{.*}})', html.find('textarea').get_text(), re.DOTALL)\n",
    "    if text:\n",
    "        return text.group(0).split('\\n')\n",
    "\n",
    "def find_real_title(url):\n",
    "    r = requests.get(url)\n",
    "    tmp = r.content.replace(b'<link rel=\"canonical\" href=\"', b'r@ndom}-=||').split(b'r@ndom}-=||')[-1]\n",
    "    idx = tmp.find(b'\"/>')\n",
    "    real_link = tmp[:idx].decode()\n",
    "    return real_link.strip('https://uk.wikipedia.org/wiki/')\n",
    "    \n",
    "def clean(entry):\n",
    "    res = entry.strip()\n",
    "    res = res.replace(\"''\", '\"').replace(\"'\", \"\")\n",
    "    res = re.sub(r'<.*?>', '', res)\n",
    "    res = re.sub(r'{{.*?}}', '', res)\n",
    "    res = res.replace('[[', '').replace(']]', '')\n",
    "    res = re.sub(r'\\[.*?\\]', '', res)\n",
    "    res = res.replace('&nbsp;', ' ')\n",
    "    if res.count('|') == 1:\n",
    "        spl = res.split('|')\n",
    "        res = '{w1} ({w2})'.format(w1=spl[0].strip(),\n",
    "                                   w2=spl[1].strip())\n",
    "    if all((c.isdigit() or c in ' ,') for c in res):\n",
    "        res = res.replace(' ', '').replace(',', '.')\n",
    "        try:\n",
    "            res = int(res)\n",
    "        except:\n",
    "            try:\n",
    "                res = float(res)\n",
    "            except:\n",
    "                res = res\n",
    "    return res\n",
    "\n",
    "def parse_card(card):\n",
    "    res_dict = OrderedDict()\n",
    "    special_entries = []\n",
    "    for line in card:\n",
    "        if not line.strip().startswith('|'):\n",
    "            continue\n",
    "        if line.count('=') != 1:\n",
    "            if ('lat' in line) and ('lon' in line):\n",
    "                res_dict['coordinates'] = line\n",
    "            special_entries.append(line)\n",
    "        else:\n",
    "            cat, entry = line.split('=')\n",
    "            cat = cat.strip(' |')\n",
    "            entry = clean(entry)\n",
    "            res_dict[cat] = entry\n",
    "    return res_dict\n",
    "\n",
    "def populate_dict(info_dict, name, url_title, base_url):\n",
    "    try:\n",
    "        initial_url = 'https://uk.wikipedia.org/wiki/{title}'.format(title=url_title)\n",
    "        real_title = find_real_title(initial_url)\n",
    "        card = get_card(base_url.format(title=real_title))\n",
    "        if not card:\n",
    "            print('Could not get card for', name)\n",
    "            return\n",
    "    except:\n",
    "        print('Problem with page', name)\n",
    "        return\n",
    "    time.sleep(0.1)\n",
    "    parsed_card = parse_card(card)\n",
    "    info_dict[name] = parsed_card\n",
    "#parse_card(card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спершу дістаємо країни."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_countries(html):\n",
    "    country_urls = []\n",
    "    seen_urls = []\n",
    "    body = html.find('div', {'id': 'bodyContent', 'class': 'mw-body-content'})\n",
    "    for li in body.find_all('li'):\n",
    "        for a in li.find_all('a'):\n",
    "            link_text = a.get_text().strip()\n",
    "            link_url = a.get('href')\n",
    "            if link_url in seen_urls:\n",
    "                continue\n",
    "            seen_urls.append(link_url)\n",
    "            if not link_text:\n",
    "                continue\n",
    "            if 'Країни з прапорцями' in link_text:\n",
    "                return country_urls\n",
    "            else:\n",
    "                if (link_text[0] == link_text[0].upper() \n",
    "                    or 'остр' in link_text) and ('wiki' in link_url):\n",
    "                    country_urls.append((link_url[6:], link_text))\n",
    "                else:\n",
    "                    continue\n",
    "    return country_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BA%D1%80%D0%B0%D1%97%D0%BD_%D1%81%D0%B2%D1%96%D1%82%D1%83\"\n",
    "r = requests.get(list_url)\n",
    "html = BeautifulSoup(r.content, \"lxml\")\n",
    "country_urls = scrape_countries(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 236/307 [03:53<01:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Шпіцбергенським трактатом\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307/307 [05:04<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "country_dict = OrderedDict()\n",
    "for url_title, name in tqdm(country_urls):\n",
    "    populate_dict(country_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'country_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4dead0625578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mallkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountry_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountry_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mallkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mallkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'country_dict' is not defined"
     ]
    }
   ],
   "source": [
    "allkeys = []\n",
    "for c in country_dict:\n",
    "    for k in country_dict[c]:\n",
    "        allkeys.append(k)\n",
    "allkeys = set(allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict = {\n",
    "    'Площа': ['area', 'area_km2', 'площа_території'],\n",
    "    'Місце за площею': ['area_rank', 'класифікація_за_розміром_території'],\n",
    "    'Густота населення': ['population_density', 'густота_заселення', 'population_density_km2'],\n",
    "    'Місце за густотою населення': ['population_density_rank', 'класифікація_за_густотою_заселення'],\n",
    "    'Населення': ['population_estimate', 'population'],\n",
    "    'Місце за населенням': ['population_estimate_rank'],\n",
    "    'Рік останнього перепису населення': ['population_census_year', 'рік_перепису_населення'],\n",
    "    'Загальновживана назва': ['common_name', 'name', 'назва'],\n",
    "    'Назва в родовому відмінку': ['common_name_g', 'назва_род', 'загальнопоширена_назва'],\n",
    "    'Офіційна назва': ['conventional_long_name', 'офіційна_назва'],\n",
    "    'Назва державною мовою': ['native_name', 'native_namekathy', 'місцева_назва', 'міцева_назва'],\n",
    "    'Національний гімн': ['national_anthem', 'національний_гімн'],\n",
    "    'Офіційні мови': ['official_languages', 'main_languages', 'languages', 'major_language',\n",
    "                      'офіційні_мови', 'working_languages'],\n",
    "    'Столиця': ['capital', 'столиця'],\n",
    "    'Координати': ['coordinates'],\n",
    "    'Найбільше місто': ['largest_city', 'найбільше_місто'],\n",
    "    'Демонім': ['demonym'],\n",
    "    'Форма правління': ['government_type', 'форма_правління'],\n",
    "    'Імена лідерів': ['імена_лідерів_країни', 'leader_names'],\n",
    "    'Посади лідерів': ['головні_керівні_посади', 'leader_titles'],\n",
    "    'Лідери': ['leaders'],\n",
    "    'Відсоток, покритий водою': ['percent_water', 'покрито_водою_відсоток'],\n",
    "    'ВВП (ПКС)': ['GDP_PPP', 'ВВП_ПКС', 'GDP'],\n",
    "    'ВВП (ПКС) на душу населення': ['GDP_PPP_per_capita', 'GDP_per_capita',\n",
    "                           'ВВП_ПКС_на_душу_населення', 'ВВП_на_душу_населення'],\n",
    "    'Місце за ВВП (ПКС)': ['GDP_PPP_rank', 'GDP_rank', 'класифікація_за_рівнем_ВВП',\n",
    "                    'класифікація_за_рівнем_ВВП_ПКС'],\n",
    "    'Індекс розвитку (HDI)': ['HDI'],\n",
    "    'Місце за індексом розвитку (HDI)': ['HDI_rank'],\n",
    "    'Валюта': ['currency', 'валюта'],\n",
    "    'Код валюти': ['currency_code', 'код_валюти'],\n",
    "    'Часовий пояс': ['time_zone', 'часовий_пояс'],\n",
    "    'UTC-поправка': ['utc_offset', 'utc_поправка'],\n",
    "    'Інтернет-домен': ['cctld', 'інтернет_домен'],\n",
    "    'Телефонний код': ['calling_code', 'телефонний_код'],\n",
    "    'Ключові події в історії': ['established_events', 'незалежність'],\n",
    "    'Ключові дати в історії': ['established_dates', 'дати_отримання_незалежності'],\n",
    "    'Ключові події і дати в історії': ['events_dates']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord(raw_coord):\n",
    "    clist = [c.strip() for c in clean(raw_coord).strip(' |').split('|')\n",
    "            if '=' in c]\n",
    "    #print(clist)\n",
    "    replace_dict = {'lat_dir': 'latNS', 'lon_dir': 'longEW',\n",
    "                    'lat_deg': 'latd', 'lat_min': 'latm',\n",
    "                    'lon_deg': 'longd', 'lon_min': 'longm'}\n",
    "    for c in clist:\n",
    "        if c in replace_dict.keys():\n",
    "            c.replace(c, replace_dict[c])\n",
    "    coord_dict = dict()\n",
    "    for c in clist:\n",
    "        if not len(c.split('=')) == 2:\n",
    "            return 'Помилка в даних: {coords}'.format(coords = ' '.join(clist))\n",
    "        k, v = c.split('=')\n",
    "        coord_dict[k.strip()] = v.strip()\n",
    "    if not 'latd' in coord_dict.keys():\n",
    "        return 'Помилка в даних: {coords}'.format(coords = ' '.join(clist))\n",
    "    directions = {\"N\": \"північної\",\n",
    "                  \"S\": \"південної\",\n",
    "                  \"E\": \"східної\",\n",
    "                  \"W\": \"західної\"}\n",
    "    try:\n",
    "        latd = coord_dict['latd']\n",
    "        latm = coord_dict['latm']\n",
    "        lat_dir = directions[coord_dict['latNS']]\n",
    "        lond = coord_dict['longd']\n",
    "        lonm = coord_dict['longm']\n",
    "        lon_dir = directions[coord_dict['longEW']]\n",
    "    except KeyError:\n",
    "        return 'Помилка в даних: {coords}'.format(coords = ' '.join(clist))\n",
    "    lat = \"{latd}° {latm}′ {lat_dir} широти\".format(latd=latd,\n",
    "                                                    latm=latm, \n",
    "                                                    lat_dir=lat_dir)\n",
    "    lon = \"{lond}° {lonm}′ {lon_dir} довготи\".format(lond=lond,\n",
    "                                                    lonm=lonm, \n",
    "                                                    lon_dir=lon_dir)\n",
    "    return lat+', '+lon\n",
    "\n",
    "directions = {\"N\": \"північної\",\n",
    "              \"S\": \"південної\",\n",
    "              \"E\": \"східної\",\n",
    "              \"W\": \"західної\",\n",
    "              \"\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_coordinates(info_dict):\n",
    "    for c in info_dict:\n",
    "        if ('longEW' in info_dict[c].keys() and 'latm' in info_dict[c].keys()\n",
    "            and 'latd' in info_dict[c].keys()):\n",
    "            latd = info_dict[c]['latd']\n",
    "            latm = info_dict[c]['latm']\n",
    "            lat_dir = directions[info_dict[c]['latNS']]\n",
    "            lond = info_dict[c]['longd']\n",
    "            lonm = info_dict[c]['longm']\n",
    "            lon_dir = directions[info_dict[c]['longEW']]\n",
    "            lat = \"{latd}° {latm}′ {lat_dir} широти\".format(latd=latd,\n",
    "                                                    latm=latm, \n",
    "                                                    lat_dir=lat_dir)\n",
    "            lon = \"{lond}° {lonm}′ {lon_dir} довготи\".format(lond=lond,\n",
    "                                                    lonm=lonm, \n",
    "                                                    lon_dir=lon_dir)\n",
    "            coord = lat+', '+lon\n",
    "            info_dict[c]['coordinates'] = coord\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_leaders(info_dict):\n",
    "    for c in info_dict:\n",
    "        titles = [info_dict[c][k] for k in info_dict[c].keys() if re.search(r'leader_title[0-9]', k)]\n",
    "        leaders = [info_dict[c][k] for k in info_dict[c].keys() if re.search(r'leader_name[0-9]', k)]\n",
    "        if not len(titles) == len(leaders):\n",
    "            continue\n",
    "        key_t = 'leader_titles'\n",
    "        key_l = 'leader_names'\n",
    "        key_tl = 'leaders'\n",
    "        info_dict[c][key_t] = ', '.join(titles)\n",
    "        info_dict[c][key_l] = ', '.join(leaders)\n",
    "        info_dict[c][key_tl] = ', '.join('{t} - {n}'.format(t=t, n=n) for (t, n) in zip(titles, leaders))\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_events(info_dict):\n",
    "    for c in info_dict:\n",
    "        events = [info_dict[c][k] for k in info_dict[c].keys() if re.search(r'established_event[0-9]', k)]\n",
    "        dates = [str(info_dict[c][k]) for k in info_dict[c].keys() if re.search(r'established_date[0-9]', k)]\n",
    "        if not len(events) == len(dates):\n",
    "            continue\n",
    "        key_e = 'established_events'\n",
    "        key_d = 'established_dates'\n",
    "        key_ed = 'events_dates'\n",
    "        info_dict[c][key_e] = ', '.join(events)\n",
    "        info_dict[c][key_d] = ', '.join(dates)\n",
    "        info_dict[c][key_ed] = ', '.join('{t} - {n}'.format(t=t, n=n) for (t, n) in zip(events, dates))\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_keys(info_dict, keydict):\n",
    "    for k, v in keydict.items():\n",
    "        for c in info_dict:\n",
    "            for oldk in v:\n",
    "                if oldk in info_dict[c].keys():\n",
    "                    info_dict[c][k] = info_dict[c][oldk]\n",
    "                    break\n",
    "    for c in info_dict:\n",
    "        info_dict[c] = {k:v for k,v in info_dict[c].items() if k in keydict}\n",
    "    for c in info_dict:\n",
    "        for k in info_dict[c]:\n",
    "            if info_dict[c][k] == '':\n",
    "                info_dict[c][k] = 'нема інформації в базі'\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = fix_coordinates(country_dict)\n",
    "country_dict = fix_events(country_dict)\n",
    "country_dict = fix_leaders(country_dict)\n",
    "country_dict = standardize_keys(country_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('countries.pkl', 'wb') as wf:\n",
    "#    pickle.dump(country_dict, wf)\n",
    "\n",
    "with open('countries.pkl', 'rb') as f:\n",
    "    country_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Міста: спершу якомога більше міст із окремих списків, потім - враховуючи неминучі втрати деяких міст - окремо міста-мільйонники і столиці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_url = 'https://uk.wikipedia.org/wiki/%D0%9A%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D1%96%D1%8F:%D0%A1%D0%BF%D0%B8%D1%81%D0%BA%D0%B8_%D0%BC%D1%96%D1%81%D1%82_%D0%B7%D0%B0_%D0%BA%D1%80%D0%B0%D1%97%D0%BD%D0%BE%D1%8E'\n",
    "r = requests.get(city_url)\n",
    "html = BeautifulSoup(r.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [01:19<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_WIKI = 'https://uk.wikipedia.org'\n",
    "city_urls = []\n",
    "for a in tqdm(html.find_all('a')):\n",
    "    if 'Міста' in a.get_text():\n",
    "        city_list_url = a.get('href')\n",
    "        list_r = requests.get(BASE_WIKI+city_list_url)\n",
    "        time.sleep(0.2)\n",
    "        list_html = BeautifulSoup(list_r.content, 'lxml')\n",
    "        body = list_html.find('div', {'id': 'bodyContent', 'class': 'mw-body-content'})\n",
    "        if not body:\n",
    "            print('Не знаходяться:', a.get_text())\n",
    "        entries = (body.find_all('li') + body.find_all('td'))\n",
    "        if not entries:\n",
    "            print('Не знаходяться:', a.get_text())\n",
    "        for entry in (body.find_all('li') + body.find_all('td')):\n",
    "            city_link = entry.find('a')\n",
    "            if not city_link:\n",
    "                continue\n",
    "            city_url = city_link.get('href')\n",
    "            if (not city_url) or (not '/wiki/' in city_url):\n",
    "                continue\n",
    "            city_name = city_link.get_text()\n",
    "            if not city_name or 'pt:' in city_name or city_name.startswith('Спис'):\n",
    "                continue\n",
    "            city_urls.append((city_name, city_url[6:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "city_info_dict = OrderedDict()\n",
    "past_urls = []\n",
    "for name, url_title in tqdm(city_urls):\n",
    "    if name.startswith('Міста ') or name.startswith('Спис'):\n",
    "        continue\n",
    "    if name == '':\n",
    "        continue\n",
    "    if url_title in past_urls:\n",
    "        continue\n",
    "    past_urls.append(url_title)\n",
    "    if 'pt:' in name:\n",
    "        continue\n",
    "    populate_dict(city_info_dict, name, url_title, BASE_URL)\n",
    "    #if not any(('населення' in k.lower() or 'population' in k.lower()) \n",
    "    #           for k in city_info_dict[name]):\n",
    "    #    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 142/385 [02:15<03:51,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Медан\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [06:07<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "million_url = 'https://uk.wikipedia.org/wiki/%D0%9C%D1%96%D1%81%D1%82%D0%B0-%D0%BC%D1%96%D0%BB%D1%8C%D0%B9%D0%BE%D0%BD%D0%BD%D0%B8%D0%BA%D0%B8_%D1%81%D0%B2%D1%96%D1%82%D1%83'\n",
    "rm = requests.get(million_url)\n",
    "msoup = BeautifulSoup(rm.content, 'lxml')\n",
    "mtable = msoup.find_all('table')[1]\n",
    "for row in tqdm(mtable.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    name = col[0].get_text()\n",
    "    name = re.sub('\\[.*\\]', '', name)\n",
    "    name = re.sub('\\(.*\\)', '', name)\n",
    "    name = name.strip(' *')\n",
    "    city_url = col[0].find('a').get('href')[6:]\n",
    "    populate_dict(city_info_dict, name, city_url, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194/194 [02:59<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "capitals_url = 'https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D1%81%D1%82%D0%BE%D0%BB%D0%B8%D1%86%D1%8C_%D0%BA%D1%80%D0%B0%D1%97%D0%BD_%D1%81%D0%B2%D1%96%D1%82%D1%83'\n",
    "rc = requests.get(capitals_url)\n",
    "csoup = BeautifulSoup(rc.content, 'lxml')\n",
    "ctable = csoup.find_all('table')[0]\n",
    "for row in tqdm(ctable.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    name = col[1].get_text()\n",
    "    name = re.sub('\\[.*\\]', '', name)\n",
    "    name = re.sub('\\(.*\\)', '', name)\n",
    "    name = name.strip(' *')\n",
    "    city_url = col[1].find('a').get('href')[6:]\n",
    "    populate_dict(city_info_dict, name, city_url, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_allkeys = []\n",
    "for c in city_info_dict:\n",
    "    for k in city_info_dict[c]:\n",
    "        city_allkeys.append(k)\n",
    "city_allkeys = Counter(city_allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Площа', 'Місце за площею', 'Густота населення', 'Місце за густотою населення', 'Населення', 'Місце за населенням', 'Рік останнього перепису населення', 'Загальновживана назва', 'Назва в родовому відмінку', 'Офіційна назва', 'Назва державною мовою', 'Національний гімн', 'Офіційні мови', 'Столиця', 'Координати', 'Найбільше місто', 'Демонім', 'Форма правління', 'Імена лідерів', 'Посади лідерів', 'Лідери', 'Відсоток, покритий водою', 'ВВП (ПКС)', 'ВВП (ПКС) на душу населення', 'Місце за ВВП (ПКС)', 'Індекс розвитку (HDI)', 'Місце за індексом розвитку (HDI)', 'Валюта', 'Код валюти', 'Часовий пояс', 'UTC-поправка', 'Інтернет-домен', 'Телефонний код', 'Ключові події в історії', 'Ключові дати в історії', 'Ключові події і дати в історії'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keydict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict['Площа'].extend(['area_municipality', 'area_urban_km2', 'area_total', 'area_metro',\n",
    "                         'area_urban', 'area_metro_km2', 'area_total_km2', \"площа\", \"площадь\",\n",
    "                         'TotalArea', \"Площа\"])\n",
    "keydict['Густота населення'].extend([\"густота\", \"густота\", \"густота населення\",\n",
    "                                     \"pop_dens\", 'population_density_urban_km2',\n",
    "                                     \"Густота\", 'Density', 'density_km2',\n",
    "                                     'Щільність населення'])\n",
    "keydict['Населення'].extend(['metro_pop', 'pop-total', 'pop_municipality', 'population_(Metro)',\n",
    "                             'population_est', 'population_metro', 'population_total',\n",
    "                             'population_urban', 'Населення', 'Population', \"населення_згідно_перепису\",\n",
    "                             \"повне_населення\"])\n",
    "keydict['Загальновживана назва'].extend(['Назва', 'Неофіційна назва',\n",
    "                                         'загальнопоширена_назва', 'назва українською',\n",
    "                                         'українська назва', 'Назва українською', 'Name',\n",
    "                                         \"назва укр.\"])\n",
    "keydict['Назва в родовому відмінку'].extend(['name_g', \"назва в родовому відмінку\",\n",
    "                                             \"Родовий відмінок\"])\n",
    "keydict['Назва державною мовою'].extend(['Місцева назва', \"місцева назва\", \"Назва оригінальна\",\n",
    "                                         \"Оригінальна назва\", \"назва мовою оригіналу\",\n",
    "                                         \"самоназва\", \"оригінальна назва\", 'name_local'])\n",
    "keydict['ВВП (ПКС)'].extend(['ввп'])\n",
    "keydict['Телефонний код'].extend([\"телефонний код\"])\n",
    "keydict['Країна'] = [\"країна\", \"Країна\"]\n",
    "keydict['Регіон'] = [\"регіон\", \"Регіон\", 'region', 'Region']\n",
    "keydict['Засноване'] = ['засноване', 'заснований', 'засновано', 'established_date']\n",
    "keydict['Міста-побратими'] = ['міста-побратими', \"міста побратими\", 'sister-cities']\n",
    "keydict['Висота над рівнем моря'] = ['elevation_m', 'elevation', 'elevation_max',\n",
    "                                    \"висота над рівнем моря\", \"висота\", \"середня висота\",\n",
    "                                    \"висота центру НП\"]\n",
    "keydict['Веб-сторінка'] = ['веб-сторінка', 'вебсайт', 'веб-сайт', 'website']\n",
    "keydict['Мер'] = ['mayor', 'Mayor', \"мер\", \"Мер\", \"голова\"]\n",
    "keydict['Девіз'] = ['девіз', 'motto']\n",
    "keydict['Поділ міста'] = ['поділ міста', 'поділ', \"внутрішній поділ\", \"внутрішній розподіл\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#city_info_dict = fix_coordinates(city_info_dict)\n",
    "city_info_dict = fix_events(city_info_dict)\n",
    "city_info_dict = fix_leaders(city_info_dict)\n",
    "city_info_dict = standardize_keys(city_info_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_city_dict = dict()\n",
    "for k in list(city_info_dict.keys()):\n",
    "    if k in country_dict.keys():\n",
    "        continue\n",
    "    else:\n",
    "        new_city_dict[k] = city_info_dict[k]\n",
    "city_info_dict = new_city_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('cities.pkl', 'wb') as wf:\n",
    "#    pickle.dump(city_info_dict, wf)\n",
    "\n",
    "with open('cities.pkl', 'rb') as f:\n",
    "    city_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Площа': 'нема інформації в базі',\n",
       " 'Населення': 3370000,\n",
       " 'Загальновживана назва': 'Варшава',\n",
       " 'Назва державною мовою': 'Warszawa',\n",
       " 'Імена лідерів': 'нема інформації в базі',\n",
       " 'Посади лідерів': 'нема інформації в базі',\n",
       " 'Лідери': 'нема інформації в базі',\n",
       " 'Ключові події в історії': 'нема інформації в базі',\n",
       " 'Ключові дати в історії': 'нема інформації в базі',\n",
       " 'Ключові події і дати в історії': 'нема інформації в базі',\n",
       " 'Країна': 'нема інформації в базі',\n",
       " 'Регіон': 'Файл:POL województwo mazowieckie flag.svg (25px Мазовецьке воєводство)',\n",
       " 'Засноване': '13 століття',\n",
       " 'Міста-побратими': 'нема інформації в базі',\n",
       " 'Висота над рівнем моря': '78-115',\n",
       " 'Веб-сторінка': 'нема інформації в базі',\n",
       " 'Мер': 'Ганна Гронкевич-Вальц',\n",
       " 'Девіз': '\"Contemnit procellas\" (Кидає виклик бурям)\"Semper invicta\" (Ніколи неприборкана)',\n",
       " 'Поділ міста': '18 районів'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_info_dict['Варшава']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Моря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_url = 'https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BC%D0%BE%D1%80%D1%96%D0%B2'\n",
    "sea_r = requests.get(sea_url)\n",
    "sea_soup = BeautifulSoup(sea_r.content, 'lxml')\n",
    "oceans = sea_soup.find_all('th')\n",
    "sea_groups = sea_soup.find_all('td')[:8]\n",
    "seas_lists = [s.find_all('li') for s in sea_groups]\n",
    "seas = [item for sublist in seas_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [01:34<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "sea_info_dict = OrderedDict()\n",
    "for o in oceans:\n",
    "    name = o.find('a').get_text().strip()\n",
    "    url_title = o.find('a').get('href')[6:]\n",
    "    populate_dict(sea_info_dict, name, url_title, BASE_URL)\n",
    "for sea in tqdm(seas):\n",
    "    name = sea.find('a').get_text().strip()\n",
    "    url_title = sea.find('a').get('href')[6:]\n",
    "    populate_dict(sea_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_oceans(info_dict):\n",
    "    for ocean in list(info_dict.keys()):\n",
    "        if not 'океан' in ocean:\n",
    "            continue\n",
    "        for k in list(info_dict[ocean].keys()):\n",
    "            if 'мітка' in k:\n",
    "                mnum = k[-1]\n",
    "                new_key = info_dict[ocean][k]\n",
    "                try:\n",
    "                    text = info_dict[ocean]['текст'+mnum]\n",
    "                    if not text: continue\n",
    "                    info_dict[ocean][new_key] = info_dict[ocean]['текст'+mnum]\n",
    "                except:\n",
    "                    continue\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_info_dict = fix_oceans(sea_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "seakeys = []\n",
    "for k in sea_info_dict:\n",
    "    seakeys.extend(list(sea_info_dict[k].keys()))\n",
    "seakeys = list(set(seakeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict['Найбільша глибина'] = ['Найбільша глибина', 'Максимальна глибина', \"максимальна глибина\",\n",
    "                                \"максимальна_глибина\", \"найбільша глибина\", \"max-depth\"]\n",
    "keydict['Середня глибина'] = ['Середня глибина', 'сер глибина', \"середня глибина\", \n",
    "                              \"середня_глибина\", \"depth\"]\n",
    "keydict['Розташування'] = ['Розташування', 'розташування', 'location']\n",
    "keydict[\"Об'єм\"] = ['Обєм', \"об'єм\", \"Об'єм\", 'volume']\n",
    "keydict['Солоність'] = ['Солоність', \"солоність\", 'salinity']\n",
    "keydict['Впадаючі річки'] = ['Витікаючі річки', 'Впадають річки', 'впадаючі річки',\n",
    "                             'Впадаючі річки', 'впадаюча річка', \"вливаються\", \"впадають\"]\n",
    "keydict['Довжина берегової лінії'] = ['Довжина берегової лінії', 'довжина берегової лінії',\n",
    "                                      'берегова_лінія', 'берегова лінія']\n",
    "keydict['Моря'] = ['Моря']\n",
    "keydict['Океан'] = ['океан']\n",
    "keydict['Країни'] = ['країни', \"країна\"]\n",
    "keydict['Площа водозабору'] = ['Площа водозбору', 'площа водозабору', 'Площа водозабору']\n",
    "keydict['Прозорість'] = ['Прозорість', \"прозорість\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sea_info_dict = standardize_keys(sea_info_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('seas.pkl', 'wb') as wf:\n",
    "#    pickle.dump(sea_info_dict, wf)\n",
    "\n",
    "with open('seas.pkl', 'rb') as f:\n",
    "    sea_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.21it/s]\n",
      "100%|██████████| 39/39 [00:33<00:00,  1.15it/s]\n",
      " 81%|████████▏ | 26/32 [00:21<00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Ямайка\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:26<00:00,  1.20it/s]\n",
      "100%|██████████| 41/41 [00:37<00:00,  1.09it/s]\n",
      "  8%|▊         | 5/60 [00:05<00:55,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Ломбок\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 39/60 [00:36<00:19,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Сан-Крістобаль\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:55<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "isl_url = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BE%D1%81%D1%82%D1%80%D0%BE%D0%B2%D1%96%D0%B2_%D0%B7%D0%B0_%D0%BF%D0%BB%D0%BE%D1%89%D0%B5%D1%8E\"\n",
    "isr = requests.get(isl_url)\n",
    "isl_soup = BeautifulSoup(isr.content, 'lxml')\n",
    "tables = isl_soup.find_all('table')\n",
    "isl_info_dict = OrderedDict()\n",
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "for table in tables[1:-1]:\n",
    "    for row in tqdm(table.find_all('tr')[1:]):\n",
    "        col = row.find_all('td')\n",
    "        name = col[1].get_text()\n",
    "        url_title = col[1].find('a').get('href')[6:]\n",
    "        populate_dict(isl_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "islkeys = []\n",
    "for k in isl_info_dict:\n",
    "    islkeys.extend(list(isl_info_dict[k].keys()))\n",
    "islkeys = list(set(islkeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict['Розташування'].extend(['Місце'])\n",
    "keydict['Площа'].extend(['Загальна площа', \"Площа\\xa0\"])\n",
    "keydict['Група островів'] = ['Група', \"група\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "isl_info_dict = standardize_keys(isl_info_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('isls.pkl', 'wb') as wf:\n",
    "#    pickle.dump(isl_info_dict, wf)\n",
    "\n",
    "with open('isls.pkl', 'rb') as f:\n",
    "    isl_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Площа': 24100,\n",
       " 'Загальновживана назва': 'Сардинія',\n",
       " 'Назва державною мовою': 'нема інформації в базі',\n",
       " 'Найбільше місто': 'Кальярі',\n",
       " 'ВВП (ПКС)': '33.6 млрд. євро',\n",
       " 'Часовий пояс': 'UTC+1 (взимку),UTC+2 (влітку)',\n",
       " 'Країна': 'нема інформації в базі',\n",
       " 'Регіон': 'Кальярі (провінція)|Кальярі,Карбонія-Іглезіас (провінція)|Карбонія-Іглезіас,Медіо-Кампідано (провінція)|Медіо-Кампідано,Нуоро (провінція)|Нуоро,Ольястра (провінція)|Ольястра,Ольбія-Темпіо (провінція)|Ольбія-Темпіо,Орістано (провінція)|Орістано,Сассарі (провінція)|Сассарі',\n",
       " 'Засноване': '26 лютого 1948(надано статус автономії)',\n",
       " 'Веб-сторінка': 'http://www.regione.sardegna.it/ www.regione.sardegna.it',\n",
       " 'Розташування': 'Regione Sardegna 3.svg',\n",
       " 'Країни': 'нема інформації в базі'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isl_info_dict['Сардинія']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Річки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_url = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D1%80%D1%96%D1%87%D0%BE%D0%BA_%D0%B7%D0%B0_%D0%B4%D0%BE%D0%B2%D0%B6%D0%B8%D0%BD%D0%BE%D1%8E\"\n",
    "rr = requests.get(river_url)\n",
    "rsoup = BeautifulSoup(rr.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 171/174 [03:04<00:03,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Ессекібо\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [03:07<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "river_info_dict = OrderedDict()\n",
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "table = rsoup.find_all('table')[1]\n",
    "for row in tqdm(table.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    rivers = col[1].find_all('a')\n",
    "    for river in rivers:\n",
    "        name = river.get_text()\n",
    "        url_title = river.get('href')[6:]\n",
    "        populate_dict(river_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivkeys = []\n",
    "for k in river_info_dict:\n",
    "    rivkeys.extend(list(river_info_dict[k].keys()))\n",
    "rivkeys = list(set(rivkeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict['Довжина'] = ['довжина']\n",
    "keydict['Розташування гирла'] = ['витік коорд', \"гирло_коорд\", \"гирло коорд\", \"витік_коорд\"]\n",
    "keydict['Гирло']  = ['гирло']\n",
    "keydict['Площа басейну'] = ['площа басейну', 'басейн', \"площа_басейну\"]\n",
    "keydict['Країни басейну'] = ['країни басейну', 'країни_басейну', 'прирічкові_країни', 'прирічкові країни']\n",
    "keydict['Стік'] = ['стік', 'максимальний_стік']\n",
    "keydict['Притоки'] = ['притоки']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "river_info_dict = standardize_keys(river_info_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('train_data/rivers.pkl', 'wb') as wf:\n",
    "#    pickle.dump(river_info_dict, wf)\n",
    "\n",
    "with open('train_data/rivers.pkl', 'rb') as f:\n",
    "    river_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Озера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_url = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BD%D0%B0%D0%B9%D0%B1%D1%96%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D0%BE%D0%B7%D0%B5%D1%80_%D1%81%D0%B2%D1%96%D1%82%D1%83\"\n",
    "lake_r = requests.get(lake_url)\n",
    "lake_soup = BeautifulSoup(lake_r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 29/87 [00:31<01:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Женевське озеро\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:39<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "lake_info_dict = OrderedDict()\n",
    "table = lake_soup.find_all('table')[1]\n",
    "for row in tqdm(table.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    lake = col[0].find('a')\n",
    "    name = lake.get_text()\n",
    "    url_title = lake.get('href')[6:]\n",
    "    populate_dict(lake_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakeys = []\n",
    "for k in lake_info_dict:\n",
    "    lakeys.extend(list(lake_info_dict[k].keys()))\n",
    "lakeys = list(set(lakeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type', 'region:EU_type:waterbody|display', 'lake_type']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in lakeys if 'typ' in k.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict[\"Загальновживана назва\"].extend(['lake_name'])\n",
    "keydict['Ширина'] = ['ширина', 'width']\n",
    "keydict['Середня глибина'].extend(['глибина'])\n",
    "keydict[\"Країни\"].extend(['countries', 'basin_countries', \"країни_басейну\", \"країни басейну\"])\n",
    "keydict[\"Міста\"] = ['cities', 'major cities', \"міста\"]\n",
    "keydict[\"Впадаючі річки\"].extend(['витікають'])\n",
    "keydict[\"Тип\"] = ['тип', 'type', 'Тип', 'lake_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_info_dict = standardize_keys(lake_info_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('lakes.pkl', 'wb') as wf:\n",
    "#    pickle.dump(lake_info_dict, wf)\n",
    "\n",
    "with open('lakes.pkl', 'rb') as f:\n",
    "    lake_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Площа': 16400,\n",
       " 'Загальновживана назва': 'Балха́ш',\n",
       " 'Назва державною мовою': 'нема інформації в базі',\n",
       " 'Висота над рівнем моря': 340,\n",
       " 'Найбільша глибина': 26,\n",
       " 'Середня глибина': 5.8,\n",
       " \"Об'єм\": 112,\n",
       " 'Впадаючі річки': 'Ілі (ріка)|Ілі, Каратал (ріка)|Каратал, Аксу (притока Балхашу)|Аксу, Лепси (ріка)|Лепси, Аягуз (річка)|Аягуз',\n",
       " 'Країни': 'Казахстан',\n",
       " 'Площа басейну': 413000,\n",
       " 'Країни басейну': 'Казахстан',\n",
       " 'Міста': 'нема інформації в базі',\n",
       " 'Тип': 'нема інформації в базі'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_info_dict['Балхаш']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гори."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mont_url = \"https://uk.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%B5%D0%BB%D1%96%D0%BA_%D0%BA%D1%80%D0%B0%D1%97%D0%BD_%D0%B7%D0%B0_%D0%BD%D0%B0%D0%B9%D0%B2%D0%B8%D1%89%D0%B8%D0%BC%D0%B8_%D1%82%D0%BE%D1%87%D0%BA%D0%B0%D0%BC%D0%B8\"\n",
    "mr = requests.get(mont_url)\n",
    "msoup = BeautifulSoup(mr.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 57/197 [00:57<02:20,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Кіньєті\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 68/197 [01:09<02:11,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for [5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [03:24<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "mont_info_dict = OrderedDict()\n",
    "table = msoup.find_all('table')[0]\n",
    "for row in tqdm(table.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    mont = col[2].find('a')\n",
    "    if not mont:\n",
    "        continue\n",
    "    name = mont.get_text()\n",
    "    url_title = mont.get('href')[6:]\n",
    "    populate_dict(mont_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mont_url2 = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%B3%D1%96%D1%80_%D0%B7%D0%B0_%D0%B2%D1%96%D0%B4%D0%BD%D0%BE%D1%81%D0%BD%D0%BE%D1%8E_%D0%B2%D0%B8%D1%81%D0%BE%D1%82%D0%BE%D1%8E\"\n",
    "mr = requests.get(mont_url2)\n",
    "msoup = BeautifulSoup(mr.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = msoup.find_all('table')[0]\n",
    "for row in tqdm(table.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    mont = col[1].find('a')\n",
    "    if not mont:\n",
    "        continue\n",
    "    name = mont.get_text()\n",
    "    url_title = mont.get('href')[6:]\n",
    "    populate_dict(mont_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/22 [00:00<00:16,  1.24it/s]\u001b[A\n",
      "100%|██████████| 22/22 [00:21<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not get card for Памір\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mont_url3 = \"https://uk.wikipedia.org/wiki/%D0%93%D1%96%D1%80%D1%81%D1%8C%D0%BA%D0%B0_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0\"\n",
    "mr = requests.get(mont_url3)\n",
    "msoup = BeautifulSoup(mr.content, 'lxml')\n",
    "table = msoup.find_all('table')[0]\n",
    "for row in tqdm(table.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    mont = col[0].find('a')\n",
    "    if not mont:\n",
    "        continue\n",
    "    name = mont.get_text()\n",
    "    url_title = mont.get('href')[6:]\n",
    "    populate_dict(mont_info_dict, name, url_title, BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkeys = []\n",
    "for k in mont_info_dict:\n",
    "    monkeys.extend(list(mont_info_dict[k].keys()))\n",
    "monkeys = list(set(monkeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keydict['Тип'].extend(['Type'])\n",
    "keydict['Гірська система'] = ['гірська_система', 'система']\n",
    "keydict['Відносна висота'] = ['відносна_висота', \"висота відносна\", \"відносна висота\"]\n",
    "keydict['Висота над рівнем моря'].extend(['найвища_висота', 'Elevation', 'highest_elevation'])\n",
    "keydict['Перше сходження'] = ['перше_сходження', 'сходження']\n",
    "keydict['Вік'] = ['Age', 'age', \"вік\", 'період', 'період1']\n",
    "keydict['Гороутворення'] = ['гороутворення', 'гороутворення1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mont_info_dict = standardize_keys(mont_info_dict, keydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('mountains.pkl', 'wb') as wf:\n",
    "    pickle.dump(mont_info_dict, wf)\n",
    "\n",
    "with open('mountains.pkl', 'rb') as f:\n",
    "    mont_info_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Загальновживана назва': 'Говерла',\n",
       " 'Країна': 'нема інформації в базі',\n",
       " 'Висота над рівнем моря': '2061 м',\n",
       " 'Країни': 'нема інформації в базі',\n",
       " 'Тип': 'нема інформації в базі',\n",
       " 'Гірська система': 'Чорногора, Українські Карпати, Карпати',\n",
       " 'Перше сходження': 'Невідомо',\n",
       " 'Вік': 'нема інформації в базі'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mont_info_dict['Говерла']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dict = {'Площа': \"км²\",\n",
    " 'Місце за площею': 'у світі',\n",
    " 'Густота населення': 'осіб на км²',\n",
    " 'Місце за густотою населення': \"у світі\",\n",
    " 'Населення': \"осіб\",\n",
    " 'Місце за населенням': \"у світі\",\n",
    " 'Рік останнього перепису населення': \"\",\n",
    " 'Загальновживана назва': \"\",\n",
    " 'Назва в родовому відмінку': \"\",\n",
    " 'Офіційна назва': \"\",\n",
    " 'Назва державною мовою': \"\",\n",
    " 'Національний гімн': \"\",\n",
    " 'Офіційні мови': \"\",\n",
    " 'Столиця': \"\",\n",
    " 'Координати': \"\",\n",
    " 'Найбільше місто': \"\",\n",
    " 'Демонім': \"\",\n",
    " 'Форма правління': \"\",\n",
    " 'Імена лідерів': \"\",\n",
    " 'Посади лідерів': \"\",\n",
    " 'Лідери': \"\",\n",
    " 'Відсоток, покритий водою': \"%\",\n",
    " 'ВВП (ПКС)': \"доларів\",\n",
    " 'ВВП (ПКС) на душу населення': \"доларів\",\n",
    " 'Місце за ВВП (ПКС)': \"у світі\",\n",
    " 'Індекс розвитку (HDI)': \"\",\n",
    " 'Місце за індексом розвитку (HDI)': \"у світі\",\n",
    " 'Валюта': \"\",\n",
    " 'Код валюти': \"\",\n",
    " 'Часовий пояс': \"\",\n",
    " 'UTC-поправка': \"год\",\n",
    " 'Інтернет-домен': \"\",\n",
    " 'Телефонний код': \"\",\n",
    " 'Ключові події в історії': \"\",\n",
    " 'Ключові дати в історії': \"\",\n",
    " 'Ключові події і дати в історії': \"\",\n",
    " 'Країна': \"\",\n",
    " 'Регіон': \"\",\n",
    " 'Засноване': \"\",\n",
    " 'Міста-побратими': \"\",\n",
    " 'Висота над рівнем моря': \"м\",\n",
    " 'Веб-сторінка': \"\",\n",
    " 'Мер': \"\",\n",
    " 'Девіз': \"\",\n",
    " 'Поділ міста': \"\",\n",
    " 'Найбільша глибина': \"м\",\n",
    " 'Середня глибина': \"м\",\n",
    " 'Розташування': \"\",\n",
    " \"Об'єм\": \"м³\",\n",
    " 'Солоність': \"‰\",\n",
    " 'Впадаючі річки': \"\",\n",
    " 'Площа басейну': \"км²\",\n",
    " 'Довжина берегової лінії': \"км\",\n",
    " 'Моря': \"\",\n",
    " 'Океан': \"\",\n",
    " 'Площа водозабору': \"км²\",\n",
    " 'Прозорість': \"\",\n",
    " 'Група островів': \"\",\n",
    " 'Країни': \"\",\n",
    " 'Ширина': \"км\",\n",
    " 'Міста': \"\",\n",
    " 'Тип': \"\",\n",
    " 'Гірська система': \"\",\n",
    " 'Відносна висота': \"м\",\n",
    " 'Перше сходження': \"\",\n",
    " 'Вік': \"\",\n",
    " 'Гороутворення': \"\"}\n",
    "\n",
    "with open('data/units.pkl', 'wb') as f:\n",
    "    pickle.dump(unit_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df['repl'] = dict_df[1].str.replace('\\(.*\\)', '')\n",
    "dict_df[dict_df[1].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "keys = []\n",
    "for f in glob.glob('dicts/*'):\n",
    "    dicname = f[5:-4]\n",
    "    dic = pickle.load(open(f, 'rb'))\n",
    "    for k in dic:\n",
    "        try:\n",
    "            keys.append((dicname, k, len(dic[k].keys())))\n",
    "        except:\n",
    "            print(k)\n",
    "            continue\n",
    "dict_df = pd.DataFrame(keys)\n",
    "disamb_dict = dict(zip(list(dict_df[0].value_counts().index),\n",
    "     ['місто/регіон', \"країна\", \"гора\", \"річка\", \"острів\", \"море\", \"озеро\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Північна Ютландія [місто/регіон]\n"
     ]
    }
   ],
   "source": [
    "unified_dict = dict()\n",
    "total_len = 0\n",
    "for f in glob.glob('data/*')[:-1]:\n",
    "    dicname = f[5:-4]\n",
    "    dic = pickle.load(open(f, 'rb'))\n",
    "    total_len += len(dic)\n",
    "    new_dict = dict()\n",
    "    for k in list(dic.keys()):\n",
    "        old_k = k\n",
    "        if '(' in k:\n",
    "            detail = re.search(r'\\((.*?)\\)', k).group(1)\n",
    "            k = re.sub(r'\\(.*?\\)', '', k).strip()\n",
    "            if k in no_touch:\n",
    "                k = old_k\n",
    "        else:\n",
    "            detail = None\n",
    "        if k in list(dict_df[dict_df[1].duplicated()][1]) or k in new_dict:\n",
    "            new_k = k + ' [{dis}]'.format(dis=disamb_dict[dicname])\n",
    "        else:\n",
    "            new_k = k\n",
    "        if new_k in new_dict:\n",
    "            print(new_k)\n",
    "        new_dict[new_k] = dic[old_k]\n",
    "        if detail:\n",
    "            new_dict[new_k]['уточнення'] = detail\n",
    "    unified_dict.update(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Загальновживана назва': 'Дніпро',\n",
       " 'Середня глибина': '6-12 м',\n",
       " 'Країни': 'нема інформації в базі',\n",
       " 'Розташування гирла': 'нема інформації в базі',\n",
       " 'Гирло': 'Дніпровсько-Бузький лиман, Чорне море',\n",
       " 'Площа басейну': '504 300 км²',\n",
       " 'Країни басейну': 'нема інформації в базі',\n",
       " 'Стік': '1670 м³/с',\n",
       " 'Притоки': '\"Праві\"'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_dict['Дніпро [річка]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = dict()\n",
    "for k in unified_dict:\n",
    "    if 'ґ' in k:\n",
    "        new_k = k.replace('ґ', 'г')\n",
    "    else:\n",
    "        new_k = k\n",
    "    new_dict[new_k] = unified_dict[k]\n",
    "    \n",
    "unified_dict = new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in unified_dict:\n",
    "    if k.replace(' [річка]', '') in river_info_dict:\n",
    "        if 'Довжина' in river_info_dict[k.replace(' [річка]', '')]:\n",
    "            unified_dict[k]['Довжина'] = river_info_dict[k.replace(' [річка]', '')]['Довжина']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/obj_dict.pkl', 'wb') as f:\n",
    "#    pickle.dump(unified_dict, f)\n",
    "\n",
    "with open('data/obj_dict.pkl', 'rb') as f:\n",
    "    unified_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.read_csv('train3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_blank(q):\n",
    "    \n",
    "    \n",
    "    res = q.replace('[', '').replace(']', '')\n",
    "    for k in blank_dict:\n",
    "        if k in res:\n",
    "            repl = random.choice(blank_dict[k])\n",
    "            res = res.replace(k, repl)\n",
    "    return res\n",
    "\n",
    "traindf['Q'] = traindf['Q'].apply(fill_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Варшава', \"Рига\", \"Мумбай\", \"Малабо\", \"Ріо-де-Жанейро\"]\n",
    "seas = ['Чорне море', \"Балтійське море\"]\n",
    "lakes = [\"Балатон\", \"Тітікака\"]\n",
    "rivers = [\"Дніпро\", \"Амазонка\", \"Янцзи\"]\n",
    "monts = [\"Риси\", \"Говерла\", \"Аконкагуа\", \"Кіліманджаро\", \"Гімалаї\"]\n",
    "islands = [\"Тасманія\", \"Сардинія\", \"Корсика\", \"Куба\", \"Ява\"]\n",
    "\n",
    "blank_dict = {\n",
    "        '[city]': cities,\n",
    "        '[sea]': seas,\n",
    "        '[lake]': lakes,\n",
    "        '[river]': rivers,\n",
    "        '[mont]': monts,\n",
    "        '[island]': islands\n",
    "    }\n",
    "\n",
    "lol = [cities, seas, lakes, rivers, monts, islands]\n",
    "for k in blank_dict:\n",
    "    for e in blank_dict[k]:\n",
    "        pass\n",
    "    \n",
    "train2 = train2.sample(frac=3, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.to_csv('train4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('train2.csv')\n",
    "train2 = pd.read_csv('train4.csv')\n",
    "train = pd.concat([train1, train2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv file for training\n",
    "with open('train_q.txt') as f:\n",
    "    train_q = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_countries = [\"Польща\", \"Ботсвана\", \"Екваторіальна Гвінея\", \"Австралія\", \"Алжир\"]\n",
    "lines = []\n",
    "for c in train_countries:\n",
    "    for q in train_q:\n",
    "        line = q.replace('+++', c)+'\\n'\n",
    "        lines.append(line)\n",
    "        \n",
    "with open('train.csv', 'w') as wf:\n",
    "    wf.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centries = []\n",
    "for c in train_countries:\n",
    "    for k in country_dict[c]:\n",
    "        centries.append((k, country_dict[c][k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkeys = []\n",
    "for c in train_countries:\n",
    "    for k in country_dict[c]:\n",
    "        tkeys.append(k)\n",
    "        \n",
    "allkeys = []\n",
    "for c in country_dict:\n",
    "    for k in country_dict[c]:\n",
    "        allkeys.append(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
