{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from polyglot.text import Text\n",
    "import requests\n",
    "import re\n",
    "import regex\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from ukr_stemmer3 import UkrainianStemmer\n",
    "from perceptron_tagger import tagger\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from tokenize_uk import tokenize_words, tokenize_sents\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_url = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BA%D1%80%D0%B0%D1%97%D0%BD_%D1%81%D0%B2%D1%96%D1%82%D1%83\"\n",
    "r = requests.get(list_url)\n",
    "html = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "country_urls = []\n",
    "for li in html.find_all('li'):\n",
    "    span = li.find('span')\n",
    "    if not span: continue\n",
    "    for a in span.find_all('a'):\n",
    "        if not a.get_text().strip():\n",
    "            continue\n",
    "        else:\n",
    "            country_urls.append((a.get('href')[6:], a.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card(url):\n",
    "    r = requests.get(url)\n",
    "    html = BeautifulSoup(r.content, 'lxml')\n",
    "    text = re.search(r'({{.*}})', html.find('textarea').get_text(), re.DOTALL)\n",
    "    if text:\n",
    "        return text.group(0).split('\\n')\n",
    "\n",
    "def clean(entry):\n",
    "    res = entry.strip()\n",
    "    pats_to_leave = re.findall(r'.*?\\[\\[.*?\\|([^\\[\\]]+)?\\]\\]', res)\n",
    "    pats_to_replace = re.findall(r'.*?(\\[\\[[^\\[\\]]+\\|.*?\\]\\])', res)\n",
    "    if not len(pats_to_leave) == len(pats_to_replace):\n",
    "        res = res\n",
    "    else:\n",
    "        for (lpat, rpat) in zip(pats_to_leave, pats_to_replace):\n",
    "            res = res.replace(rpat, lpat)\n",
    "    res = res.replace(\"''\", '\"').replace(\"'\", \"\")\n",
    "    res = re.sub(r'<ref>.*?</ref>', '', res)\n",
    "    res = re.sub(r'<.*?>', '', res)\n",
    "    res = re.sub(r'{{.*?}}', '', res)\n",
    "    res = res.replace('[[', '').replace(']]', '')\n",
    "    res = re.sub(r'\\[.*?\\]', '', res)\n",
    "    res = res.replace('&nbsp;', ' ')\n",
    "    if res.count('|') == 1:\n",
    "        spl = res.split('|')\n",
    "        res = '{w1} ({w2})'.format(w1=spl[0].strip(),\n",
    "                                   w2=spl[1].strip())\n",
    "    if all((c.isdigit() or c in ' ,') for c in res):\n",
    "        res = res.replace(' ', '').replace(',', '.')\n",
    "        try:\n",
    "            res = int(res)\n",
    "        except:\n",
    "            try:\n",
    "                res = float(res)\n",
    "            except:\n",
    "                res = res\n",
    "    return res\n",
    "\n",
    "def parse_card(card):\n",
    "    res_dict = OrderedDict()\n",
    "    special_entries = []\n",
    "    for line in card:\n",
    "        if not line.startswith('|'):\n",
    "            continue\n",
    "        if line.count('=') != 1:\n",
    "            if ('lat' in line) and ('lon' in line):\n",
    "                res_dict['coordinates'] = line\n",
    "            special_entries.append(line)\n",
    "        else:\n",
    "            cat, entry = line.split('=')\n",
    "            cat = cat.strip(' |')\n",
    "            entry = clean(entry)\n",
    "            res_dict[cat] = entry\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:04<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "card_dict = OrderedDict()\n",
    "lake_url = \"https://uk.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BD%D0%B0%D0%B9%D0%B1%D1%96%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D0%BE%D0%B7%D0%B5%D1%80_%D1%81%D0%B2%D1%96%D1%82%D1%83\"\n",
    "lake_r = requests.get(lake_url)\n",
    "lake_soup = BeautifulSoup(lake_r.content, 'lxml')\n",
    "BASE_URL = 'https://uk.wikipedia.org/w/index.php?title={title}&action=edit&section=0'\n",
    "table = lake_soup.find_all('table')[1]\n",
    "for row in tqdm(table.find_all('tr')[1:]):\n",
    "    col = row.find_all('td')\n",
    "    lake = col[0].find('a')\n",
    "    name = lake.get_text()\n",
    "    url_title = lake.get('href')[6:]\n",
    "    try:\n",
    "        card = get_card(BASE_URL.format(title=url_title))\n",
    "        lines = []\n",
    "        for line in card:\n",
    "            if line and not line.startswith('|'):\n",
    "                line = clean(line)\n",
    "                lines.append(line)\n",
    "        card_dict[name] = lines\n",
    "    except:\n",
    "        continue\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in card_dict:\n",
    "    card_dict[c] = [line for line in card_dict[c] if len(line) > 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(card_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "entities = []\n",
    "for c in card_dict:\n",
    "    for line in card_dict[c]:\n",
    "        text = Text(line, hint_language_code='uk')\n",
    "        texts.append(text)\n",
    "        entities.append(text.entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_lists = []\n",
    "for (text, ents) in zip(texts, entities):\n",
    "    ent_list = [None] * len(text.words)\n",
    "    lower = 0\n",
    "    for ent in ents:\n",
    "        upper = ent.start\n",
    "        ent_list[lower:upper] = ['-']*(upper-lower)\n",
    "        ent_list[upper:ent.end] = [e+' | '+ent.tag for e in ent]\n",
    "        lower = ent.end\n",
    "    ent_list[lower:] = ['-']*((len(ent_list)+1)-lower)\n",
    "    ner_lists.append(list(zip(text.words, ent_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.DataFrame()\n",
    "for ner_list in ner_lists:\n",
    "    ner_to_df = pd.DataFrame(ner_list)\n",
    "    ner_df = ner_df.append(ner_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(string):\n",
    "    string = re.sub(\"а́\", 'а', string)\n",
    "    string = re.sub(\"ю́\", 'ю', string)\n",
    "    string = re.sub(\"у́\", 'у', string)\n",
    "    string = re.sub(\"о́\", 'о', string)\n",
    "    string = re.sub(\"и́\", 'и', string)\n",
    "    string = re.sub(\"е́\", 'е', string)\n",
    "    string = re.sub(\"я́\", 'я', string)\n",
    "    string = re.sub('́', '', string)\n",
    "\n",
    "    return string\n",
    "\n",
    "ner_df[0] = ner_df[0].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df.to_csv('NER_train_lakes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_ann1 = pd.read_csv('NER_train.csv')\n",
    "ner_ann2 = pd.read_csv('NER_train_cities.csv')\n",
    "ner_ann3 = pd.read_csv('NER_train_islands.csv')\n",
    "ner_ann4 = pd.read_csv('NER_train_lakes.csv')\n",
    "ner_ann5 = pd.read_csv('NER_train_rivers.csv')\n",
    "ner_ann6 = pd.read_csv('NER_train_seas.csv')\n",
    "ner_ann = pd.concat([ner_ann1, ner_ann2, ner_ann3, ner_ann4, ner_ann5, ner_ann6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_ann['anns'] = ner_ann['anns'].fillna('-')\n",
    "ner_ann = ner_ann[ner_ann['words'] != '<S>']\n",
    "ner_ann = ner_ann[ner_ann['words'] != '</S>']\n",
    "ner_ann = ner_ann[~ner_ann['words'].str.contains(r'^2C.*')]\n",
    "ner_ann['words'] = ner_ann['words'].str.replace(r'[•°′]', '.')\n",
    "ner_ann = ner_ann.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = tagger.PerceptronTagger()\n",
    "def get_ner_features(word, prev_word, next_word):\n",
    "    features = {\n",
    "        'word': word,\n",
    "        'word_stem': UkrainianStemmer(word).stem_word(),\n",
    "        'prev_word': prev_word,\n",
    "        'next_word': next_word,\n",
    "        'prev_stem': UkrainianStemmer(prev_word).stem_word(),\n",
    "        'next_stem': UkrainianStemmer(next_word).stem_word(),\n",
    "        'is_uppercase': word.title() == word,\n",
    "        'is_after_punct': prev_word in string.punctuation,\n",
    "        'is_after_uppercase': prev_word.title() == prev_word,\n",
    "        'is_before_uppercase': next_word.title() == next_word,\n",
    "        'pos': pos_tagger.tag(' '.join([prev_word, word, next_word]))[1][1]\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26419"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = []\n",
    "all_labels = []\n",
    "for i, row in ner_ann.iterrows():\n",
    "    label = row['anns']\n",
    "    word = row['words']\n",
    "    if i == 0:\n",
    "        prev_word = '.'\n",
    "    else:\n",
    "        prev_word = ner_ann['words'][i-1]\n",
    "    if i == len(ner_ann) - 1:\n",
    "        next_word = '.'\n",
    "    else:\n",
    "        next_word = ner_ann['words'][i+1]\n",
    "    features = get_ner_features(word, prev_word, next_word)\n",
    "    all_feats.append(features)\n",
    "    all_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "clf = LogisticRegression(penalty='l1')\n",
    "model = Pipeline([('vec', vec), ('clf', clf)])\n",
    "model.fit(all_feats, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_recognize(sent, model):\n",
    "    tokens = tokenize_words(sent)\n",
    "    feats = []\n",
    "    for (i, t) in enumerate(tokens):\n",
    "        if i == 0:\n",
    "            prev_word = '.'\n",
    "        else:\n",
    "            prev_word = tokens[i-1]\n",
    "        if i == len(tokens)-1:\n",
    "            next_word = '.'\n",
    "        else:\n",
    "            next_word = tokens[i+1]\n",
    "        feats.append(get_ner_features(t, prev_word, next_word))\n",
    "    labels = model.predict(feats)\n",
    "    return list(zip(tokens, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_questions.txt', 'r') as f:\n",
    "    tq = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('яка', '-'), ('площа', '-'), ('Мексики', 'LOC')]\n",
      "[('яка', '-'), ('площа', '-'), ('території', '-'), ('Португалії', 'LOC')]\n",
      "[('яка', '-'), ('територія', '-'), ('Гвінеї', 'LOC')]\n",
      "[('який', '-'), ('розмір', '-'), ('Гвінеї', 'LOC')]\n",
      "[('яка', '-'), ('столиця', '-'), ('Мексики', 'LOC')]\n",
      "[('яке', '-'), ('місто', '-'), ('є', '-'), ('столиця', '-'), ('Мексики', 'LOC')]\n",
      "[('яка', '-'), ('офіційна', '-'), ('мова', '-'), ('Австралії', 'LOC')]\n",
      "[('яка', '-'), ('мова', '-'), ('визнана', '-'), ('в', '-'), ('Мексиці', 'LOC'), ('офіційною', '-'), ('?', '-')]\n",
      "[('яка', '-'), ('форма', '-'), ('правління', '-'), ('Мексики', 'LOC')]\n",
      "[('хто', '-'), ('є', '-'), ('президентом', '-'), ('України', 'LOC')]\n",
      "[('хто', '-'), ('польский', '-'), ('президент', '-'), ('?', '-')]\n",
      "[('коли', '-'), ('відбулося', '-'), ('хрещення', '-'), ('Гвінеї', 'LOC')]\n",
      "[('у', '-'), ('якому', '-'), ('році', '-'), ('відбулось', '-'), ('хрещення', '-'), ('Гвінеї', 'LOC')]\n",
      "[('яка', '-'), ('чисельність', '-'), ('населення', '-'), ('Гвінеї', 'LOC')]\n",
      "[('скільки', '-'), ('людей', '-'), ('проживає', '-'), ('в', '-'), ('України', 'LOC')]\n",
      "[('яка', '-'), ('густота', '-'), ('населення', '-'), ('Австралії', 'LOC')]\n",
      "[('який', '-'), ('ВВП', '-'), ('на', '-'), ('душу', '-'), ('населення', '-'), ('у', '-'), ('Гвінеї', 'LOC')]\n",
      "[('який', '-'), ('повний', '-'), ('ВВП', '-'), ('Ботсвани', 'LOC')]\n",
      "[('яка', '-'), ('валюта', '-'), ('Ботсвани', 'LOC')]\n",
      "[('як', '-'), ('називається', '-'), ('валюта', '-'), (',', '-'), ('яку', '-'), ('використовують', '-'), ('у', '-'), ('Португалії', 'LOC')]\n",
      "[('який', '-'), ('часовий', '-'), ('пояс', '-'), ('Мексики', 'LOC')]\n",
      "[('який', '-'), ('домен', '-'), ('України', 'LOC')]\n",
      "[('який', '-'), ('телефонний', '-'), ('код', '-'), ('Ботсвани', 'LOC')]\n",
      "[('які', '-'), ('офіційні', '-'), ('мови', '-'), ('Гвінеї', 'LOC')]\n",
      "[('чи', '-'), ('належить', '-'), ('німецька', '-'), ('до', '-'), ('офіційних', '-'), ('мов', '-'), ('Австралії', 'LOC')]\n",
      "[('столицею', '-'), ('якої', '-'), ('країни', '-'), ('є', '-'), ('Тегусігальпа', 'LOC')]\n",
      "[('в', '-'), ('якому', '-'), ('регіоні', '-'), ('розміщена', '-'), ('Вінниця', 'LOC')]\n",
      "[('який', '-'), ('девіз', '-'), ('Вінниці', 'LOC')]\n",
      "[('коли', '-'), ('було', '-'), ('засновано', '-'), ('Вінницю', 'LOC')]\n",
      "[('у', '-'), ('якому', '-'), ('столітті', '-'), ('було', '-'), ('засновано', '-'), ('Париж', 'LOC')]\n",
      "[('яке', '-'), ('населення', '-'), ('Сакраменто', 'LOC')]\n",
      "[('скільки', '-'), ('людей', '-'), ('живе', '-'), ('у', '-'), ('Пекіні', 'LOC')]\n",
      "[('скільки', '-'), ('людей', '-'), ('мешкає', '-'), ('у', '-'), ('Римі', 'LOC')]\n",
      "[('скільки', '-'), ('людей', '-'), ('проживає', '-'), ('в', '-'), ('агломерації', '-'), ('Пекіну', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('площа', '-'), ('Вінниці', 'LOC')]\n",
      "[('який', '-'), ('розмір', '-'), ('Сакраменто', 'LOC')]\n",
      "[('яка', '-'), ('площа', '-'), ('території', '-'), ('Сакраменто', 'LOC')]\n",
      "[('яка', '-'), ('густота', '-'), ('населення', '-'), ('Монтевідео', 'LOC')]\n",
      "[('які', '-'), ('поштові', '-'), ('індекси', '-'), ('Риму', 'LOC')]\n",
      "[('який', '-'), ('телефонний', '-'), ('код', '-'), ('Монтевідео', 'LOC')]\n",
      "[('який', '-'), ('часовий', '-'), ('пояс', '-'), ('Вінниці', 'LOC')]\n",
      "[('які', '-'), ('номери', '-'), ('автомобілів', '-'), ('Вінниці', 'LOC')]\n",
      "[('які', '-'), ('водойми', '-'), ('є', '-'), ('у', '-'), ('Пекіні', 'LOC')]\n",
      "[('скільки', '-'), ('районів', '-'), ('є', '-'), ('у', '-'), ('Монтевідео', 'LOC')]\n",
      "[('який', '-'), ('поділ', '-'), ('міста', '-'), ('Тегусігальпа', 'LOC')]\n",
      "[('які', '-'), ('міста', '-'), ('-', '-'), ('побратими', '-'), ('є', '-'), ('у', '-'), ('Пекіна', 'LOC')]\n",
      "[('хто', '-'), ('є', '-'), ('мером', '-'), ('Парижа', 'LOC')]\n",
      "[('як', '-'), ('звуть', '-'), ('мера', '-'), ('Пекіна', 'LOC')]\n",
      "[('яка', '-'), ('веб', '-'), ('-', '-'), ('сторінка', '-'), ('Тегусігальпа', 'LOC')]\n",
      "[('де', '-'), ('розташоване', '-'), ('Китайське', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('в', '-'), ('якій', '-'), ('частині', '-'), ('світу', '-'), ('розташоване', '-'), ('Середземне', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('довжина', '-'), ('Чорного', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('наскільки', '-'), ('довге', '-'), ('Арабське', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('площа', '-'), ('Жовтого', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('яку', '-'), ('територію', '-'), ('займає', '-'), ('Жовте', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('найбільша', '-'), ('глибина', '-'), ('Жовтого', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('наскільки', '-'), ('глибоке', '-'), ('Середземне', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('глибина', '-'), ('найглибшої', '-'), ('точки', '-'), ('Китайського', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('як', '-'), ('глибоко', '-'), ('знайходиться', '-'), ('найглибша', '-'), ('точка', '-'), ('Чорного', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('середня', '-'), ('глибина', '-'), ('Середземного', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('який', '-'), (\"об'єм\", '-'), ('Арабського', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('який', '-'), (\"об'єм\", '-'), ('займає', '-'), ('Жовте', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('яка', '-'), ('ширина', '-'), ('Середземного', 'LOC'), ('моря', 'LOC'), ('?', '-')]\n",
      "[('наскільки', '-'), ('широке', '-'), ('Китайське', 'LOC'), ('море', 'LOC'), ('?', '-')]\n",
      "[('звідки', '-'), ('витікає', '-'), ('Дніпро', 'LOC')]\n",
      "[('де', '-'), ('розміщений', '-'), ('витік', '-'), ('Рейну', 'LOC')]\n",
      "[('які', '-'), ('координати', '-'), ('витоку', '-'), ('Меконга', 'LOC')]\n",
      "[('яка', '-'), ('широта', '-'), ('витоку', '-'), ('Рейну', 'LOC')]\n",
      "[('яка', '-'), ('довгота', '-'), ('витоку', '-'), ('Рони', 'LOC')]\n",
      "[('яка', '-'), ('висота', '-'), ('витоку', '-'), ('Меконга', 'LOC')]\n",
      "[('що', '-'), ('є', '-'), ('гирлом', '-'), ('Амазонки', 'LOC')]\n",
      "[('де', '-'), ('знаходиться', '-'), ('гирло', '-'), ('Дніпра', 'LOC')]\n",
      "[('які', '-'), ('координати', '-'), ('гирла', '-'), ('Конго', 'LOC')]\n",
      "[('яка', '-'), ('широта', '-'), ('гирла', '-'), ('Хуанхе', 'LOC')]\n",
      "[('яка', '-'), ('довгота', '-'), ('гирла', '-'), ('Рейну', 'LOC')]\n",
      "[('яка', '-'), ('площа', '-'), ('басейну', '-'), ('Рейну', 'LOC')]\n",
      "[('яку', '-'), ('територію', '-'), ('займає', '-'), ('басейн', '-'), ('Меконга', 'LOC')]\n",
      "[('скільки', '-'), ('квадратних', '-'), ('кілометрів', '-'), ('займає', '-'), ('басейн', '-'), ('Конго', 'LOC')]\n",
      "[('що', '-'), ('є', '-'), ('басейном', '-'), ('Рони', 'LOC')]\n",
      "[('яке', '-'), ('море', 'LOC'), ('є', '-'), ('басейном', '-'), ('Дніпра', 'LOC')]\n",
      "[('через', '-'), ('які', '-'), ('країни', '-'), ('протікає', '-'), ('Хуанхе', 'LOC')]\n",
      "[('яка', '-'), ('довжина', '-'), ('Конго', 'LOC')]\n",
      "[('у', '-'), ('якому', '-'), ('регіоні', '-'), ('тече', '-'), ('Дніпро', 'LOC')]\n",
      "[('як', '-'), ('називається', '-'), ('регіон', '-'), (',', '-'), ('по', '-'), ('якому', '-'), ('протікає', '-'), ('Хуанхе', 'LOC')]\n",
      "[('який', '-'), ('середнорічний', '-'), ('стік', '-'), ('Хуанхе', 'LOC')]\n",
      "[('який', '-'), ('обсяг', '-'), ('середньорічного', '-'), ('стоку', '-'), ('Рейну', 'LOC')]\n",
      "[('які', '-'), ('притоки', '-'), ('має', '-'), ('Хуанхе', 'LOC')]\n",
      "[('які', '-'), ('водойми', '-'), ('є', '-'), ('в', '-'), ('руслі', '-'), ('Хуанхе', 'LOC')]\n",
      "[('в', '-'), ('якій', '-'), ('країні', '-'), ('розміщена', '-'), ('Говерла', 'LOC')]\n",
      "[('в', '-'), ('якому', '-'), ('регіоні', '-'), ('знаходиться', '-'), ('Говерла', 'LOC')]\n",
      "[('де', '-'), ('розташований', '-'), ('Еверест', 'LOC')]\n",
      "[('в', '-'), ('якій', '-'), ('системі', '-'), ('розташована', '-'), ('Говерла', 'LOC')]\n",
      "[('частиною', '-'), ('якої', '-'), ('системи', '-'), ('є', '-'), ('Еверест', 'LOC')]\n",
      "[('до', '-'), ('якої', '-'), ('системи', '-'), ('належить', '-'), ('Кіліманджаро', 'LOC')]\n",
      "[('до', '-'), ('якого', '-'), ('типу', '-'), ('належить', '-'), ('Монблан', 'LOC')]\n",
      "[('який', '-'), ('тип', '-'), ('Монблан', 'LOC')]\n",
      "[('що', '-'), ('таке', '-'), ('Говерла', 'LOC')]\n",
      "[('з', '-'), ('якого', '-'), ('матеріалу', '-'), ('складається', '-'), ('Еверест', 'LOC')]\n",
      "[('з', '-'), ('чого', '-'), ('складається', '-'), ('Монблан', 'LOC')]\n",
      "[('яка', '-'), ('висота', '-'), ('Говерли', 'LOC')]\n",
      "[('яка', '-'), ('відносна', '-'), ('висота', '-'), ('Монблану', 'LOC')]\n",
      "[('наскільки', '-'), ('висока', '-'), ('Кіліманджаро', 'LOC')]\n",
      "[('коли', '-'), ('відбулось', '-'), ('перше', '-'), ('сходження', '-'), ('на', '-'), ('Еверест', 'LOC')]\n",
      "[('у', '-'), ('якому', '-'), ('році', '-'), ('було', '-'), ('перше', '-'), ('сходження', '-'), ('на', '-'), ('Кіліманджаро', 'LOC')]\n",
      "[('у', '-'), ('якому', '-'), ('році', '-'), ('людина', '-'), ('вперше', '-'), ('побувала', '-'), ('на', '-'), ('вершині', '-'), ('Говерли', 'LOC')]\n",
      "[('де', '-'), ('розташований', '-'), ('Балатон', 'LOC')]\n",
      "[('які', '-'), ('координати', '-'), ('Байкалу', 'LOC')]\n",
      "[('в', '-'), ('якій', '-'), ('країні', '-'), ('розташована', '-'), ('Тітікака', 'LOC')]\n",
      "[('що', '-'), ('таке', '-'), ('Тітікака', 'LOC')]\n",
      "[('до', '-'), ('якого', '-'), ('типу', '-'), ('належить', '-'), ('Тітікака', 'LOC')]\n",
      "[('яким', '-'), ('озером', '-'), ('є', '-'), ('Тітікака', 'LOC')]\n",
      "[('які', '-'), ('прибережні', '-'), ('країни', '-'), ('Тітікаки', 'LOC')]\n",
      "[('які', '-'), ('розміри', '-'), ('Тітікаки', 'LOC')]\n",
      "[('яка', '-'), ('висота', '-'), ('над', '-'), ('рівнем', '-'), ('моря', '-'), ('Гурону', 'LOC')]\n",
      "[('наскільки', '-'), ('високо', '-'), ('над', '-'), ('рівнем', '-'), ('моря', '-'), ('розміщений', '-'), ('Байкал', 'LOC')]\n",
      "[('яка', '-'), ('площа', '-'), ('поверхні', '-'), ('Балатона', 'LOC')]\n",
      "[('яку', '-'), ('площу', '-'), ('займає', '-'), ('Ківу', 'LOC')]\n",
      "[('яку', '-'), ('територію', '-'), ('займає', '-'), ('Тітікака', 'LOC')]\n",
      "[('наскільки', '-'), ('глибоке', '-'), ('Балатон', 'LOC')]\n",
      "[('яка', '-'), ('максимальна', '-'), ('глибина', '-'), ('Тітікаки', 'LOC')]\n",
      "[('яка', '-'), ('ширина', '-'), ('Байкалу', 'LOC')]\n",
      "[('наскільки', '-'), ('широке', '-'), ('Байкал', 'LOC')]\n",
      "[('який', '-'), (\"об'єм\", '-'), ('Балатона', 'LOC')]\n",
      "[('який', '-'), (\"об'єм\", '-'), ('займає', '-'), ('Балатон', 'LOC')]\n",
      "[('які', '-'), ('річки', '-'), ('витікають', '-'), ('з', '-'), ('Гурону', 'LOC')]\n",
      "[('які', '-'), ('міста', '-'), ('розташовані', '-'), ('на', '-'), ('берегах', '-'), ('Балатона', 'LOC')]\n",
      "[('які', '-'), ('міста', '-'), ('знаходяться', '-'), ('поряд', '-'), ('з', '-'), ('Ківу', 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "for q_text in tq[:-1]:\n",
    "    print(ner_recognize(q_text, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NER_model.pkl']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'NER_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
